---
title: "Trabajo de Evaluación Continua de Modelos de Regresión"
subtitle: Curso 2021/2022
author: "Xiana Carrera Alonso, Pablo Díaz Viñambres"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Poner introducción aquí


Además, en este tipo de documentos también puedes emplear sintaxis de LaTeX como ecuaciones:

$$
\begin{cases}
H_0: \beta_1=0,\\
H_a: \beta_1\neq 0
\end{cases}
$$
o tablas:
\begin{center}
\begin{tabular}{ |c c c| }
 \hline
 celda1 & celda2 & celda3 \\
 \hline
 celda4 & celda5 & celda6 \\  
 celda7 & celda8 & celda9 \\   
  \hline
\end{tabular}
\end{center}


## Incluir gráficos

Por otra parte, también puedes incluir representaciones gráficas en tu documento empleando la sintaxis:

```{r pressure, echo=FALSE}
boxplot(cars$dist)
```

Fíjate que añadiendo el parámetro `echo = FALSE' en las opciones del \emph{chuck} evitamos que se imprima el código de R que empleamos para generar la representación gráfica.


En primer lugar, leemos los datos del archivo y los colocamos en las variables X e Y.
Asimismo, leemos el número de datos n.

```{r cars}
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # Configurar wd a la carpeta actual (solo en RStudio) 
setwd("C:\\Users\\Pablo\\Desktop\\IE_Regresion")
datos <- read.table("datos_trabajo_temas6y7.txt", header=T, sep=" ", dec=".")
str(datos)
summary(datos)
head(datos)


datos = datos[,c("X", "Y47")]
str(datos)
X <- datos[,"X"]
Y <- datos[,"Y47"]

n <- length(Y)
```

## Ejercicio 2
En primer lugar, calculamos la covarianza y el coeficiente de correlación de los datos,
con el objetivo de ver si existe relación lineal entre las variables.

```{r cars}
covar = cov(X,Y)*(n-1)/n; covar           # Covarianza
cov(X,Y)                                  # Cuasicovarianza
cor(X, Y)                                 # Coeficiente de correlación
```

A  continuación hallamos el vector de medias o centro de gravedad 
para añadirlo posteriormente a la gráfica:

```{r cars}
mX <- mean(X)
mY <- mean(Y)
```

Y con la siguiente función generamos la gráfica de dispersión básica:

```{r pressure, echo = FALSE}
representar <- function(){
  plot(X, Y,
       main="Diagrama de dispersión", pch=16,
       sub="Subtítulo")
  
  # Añadimos un punto para el vector de medias
  points(mX, mY, pch=12, col=3, cex=2)
  
  # Añadimos dos rectas para dividir en cuadrantes
  abline(v=mX, col=3, lty=1, lwd=2)   # Vertical
  abline(h=mY, col=3, lty=1, lwd=2)   # Horizontal
  
  
  grid(nx = NULL, ny = NULL, lty = 2, col = "lightgray", lwd = 1)
}

representar()
```

Finalmente, establecemos el modelo lineal entre los datos 
```{r cars}
modelo=lm(Y~X)
modelo
```

## Ejercicio 2
### Estimación puntual a mano
Para la estimación puntual de los parámetros intercepto $\beta_0$, pendiente
$beta_1$ y varianza del error $\sigma^2$ podemos aplicar directamente las fórmulas
obtenidas en la parte teórica de la asignatura:
```{r cars}
var.X <- var(X)*(n-1)/n
beta0.gorro = mY - covar*mX/var.X; beta0.gorro
beta1.gorro = covar/var.X; beta1.gorro
var.error = sum((Y - beta0.gorro - beta1.gorro*X)^2)/(n-2); var.error
sd.error = sqrt(var.error); sd.error
```

### Estimación puntual automática
De manera alternativa, podemos obtenrlas a partir del propio modelo creado anteriomente por $\mathbb{R}$:
```{r cars}
modelo    # Información del modelo
modelo$coefficients         # beta0 gorro y beta1 gorro

# En modelo$residuals están los residuos
sum(modelo$residuals^2)/(n-2)
```


```{r pressure, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Incluimos también una gráfica adicional usando la librería _ggplot2_ e incluyendo la región
o intervalo de confianza para los datos al nivel del 99%:
```{r pressure, echo=FALSE}
library(ggplot2)
p3 <- ggplot(datos, aes(x=X, y=Y)) +
  geom_point() +
  geom_smooth(formula=y~x, level=0.99, method=lm, color="red", fill="#666666", se=TRUE) + 
  labs(y = "Variable respuesta",
       x = "Variable explicativa",
       title = "Modelo lineal simple, con región de confianza al 95%")
p3
```

## Ejercicio 3
### A mano
En el siguiente apartado, En primer lugar, establecemos el nivel de significación $\alfa$.
```{r cars}
alfa <- 1 - 0.99
```

A continuación, hallamos los intervalos para 
El pivote es ((PASAR A LATEX)) beta0.gorro - beta0/(sqrt(var.gorro*(1/n+mX^2/(n*var.X))) que es una
T de Student con n-2 grados de libertad

```{r cars}
beta0.cuantil <- qt(1-alfa/2, df=n-2); beta0.cuantil
beta0.extremoinferior <- beta0.gorro - beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.extremosuperior <- beta0.gorro + beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.IC <- c(beta0.extremoinferior, beta0.extremosuperior); beta0.IC
```

El pivote es ((PASAR A LATEX)) pivote beta1.gorro - beta1/sqrt(var.gorro/ (var.X * n)) que es una
T de Student con n-2 grados de libertad

```{r cars}
beta1.cuantil <- beta0.cuantil
beta1.extremoinferior <- beta1.gorro - beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.extremosuperior <- beta1.gorro + beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.IC <- c(beta1.extremoinferior, beta1.extremosuperior); beta1.IC
```

El pivote para la varianza del error será ((PASAR A LATEX))
pivote -> (n-2)*var.error^2/varianzaerror^2 que es una chi-cuadrado con n-2
grados de libertad
```{r cars}
var.error.cuantilinferior <- qchisq(alfa/2, df=n-2)
var.error.cuantilsuperior <- qchisq(1-alfa/2, df=n-2)
var.error.extremoinferior <- (n-2)*var.error^2/var.error.cuantilsuperior
var.error.extremosuperior <- (n-2)*var.error^2/var.error.cuantilinferior
var.error.IC <- c(var.error.extremoinferior, var.error.extremosuperior); var.error.IC
```

Pero también podemos utilizar las funciones de R para hacerlo de forma automática:
- IC para beta0 y beta1 asumiendo que la varianza es desconocida
```{r cars}
confint(modelo, level=0.99)
```

No hay una automatización del cálculo de la varianza del error

# Ejercicio 4
A continuación, realizaremos los contrastes de significación sobre el modelo con el objetivo de determinar si el modelo se podría simplificar a uno con menos variables o no.
En primer lugar, realizaremos el contraste de forma manual a partir de los estadísticos de contraste basado en el pivote de la estimaciones puntuales previas:
```{r cars}
#contraste de significacion para beta0
beta0.t <- abs(beta0.gorro) / (sqrt(var.error * (1/n + mX^2/(n*var.X)))); beta0.t
beta1.t <- abs(beta1.gorro) / (sd.error / sqrt(n*var.X)); beta1.t
beta0.t > beta0.cuantil # TRUE --> Aceptamos la hipótesis nula de que el modelo tiene origen distinto de 0 
beta1.t > beta1.cuantil # TRUE --> Aceptamos la hipótesis nula de que el modelo depende de la variable X
dt(beta0.t, df=n-2); # El p-valor es 0 --> La hipótesis nula es cierta para cualquier nivel de signif.

```

```
```{r cars}
summary(modelo)
```

#*******************************************************************************
# Ejercicio 5
#*******************************************************************************

x0 <- c(2, 4, 6)

y0.tilde <- beta0.gorro + beta1.gorro * x0


#*********** IC







# Con qué nivel de confianza?
predict(modelo, newdata=data.frame("X"=x0), interval = "confidence", level=0.99)
predict(modelo, newdata=data.frame("X"=x0, interval = "prediction"), level=0.99)





# Ejercicio 7
  Las técnicas de inferencia empleadas hasta el momento son ciertas bajo el supuesto de que las 4 hipótesis del modelo de regresión lineal simple (linealidad, homocedasticidad, normalidad e independencia) se verifican. De lo contrario,
  no todas las interpretaciones obtenidas seguirían siendo válidas. Por ejemplo, si no se cumplieran las hipótesis de homocedasticidad, normalidad e independencia, los intervalos de confianza que hemos obtenido no serían válidos.

## Linealidad
En primer lugar, podemos tratar de aventurar si se los datos siguen una tendencia lineal a través de una interpretación gráfica. Para ello, revisitemos la representación previamente definida, y creemos también una nueva gráfica en la que contrapongamos los residuos a los valores de X.

```{r pressure, echo=FALSE}
par(mfrow=c(1,2))

representar()
abline(modelo, col="red", lwd=2)


residuos <- Y - beta0.gorro - beta1.gorro*X
plot(X, residuos,
     main="Diagrama de dispersión", pch=16,
     sub="Subtítulo")
abline(h=0, col="red", lwd=2)

par(mfrow=c(1,1))
```


Con el objetivo de realizar una prueba rigurosa, planteamos el siguiente contraste de hipótesis:
$$
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=m(X)+\epsilon
\end{cases}
$$

Haciendo uso del paquete _sm_, realizamos la prueba de hipótesis:
```{r cars}
library(sm)
sm.regression(X, Y, model="linear")
```

La interp

