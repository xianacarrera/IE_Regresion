% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Trabajo de Evaluación Continua de Modelos de Regresión},
  pdfauthor={Xiana Carrera Alonso, Pablo Díaz Viñambres},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Trabajo de Evaluación Continua de Modelos de Regresión}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Curso 2021/2022}
\author{Xiana Carrera Alonso, Pablo Díaz Viñambres}
\date{}

\begin{document}
\maketitle

\hypertarget{introducciuxf3n}{%
\section{Introducción}\label{introducciuxf3n}}

En este documento se describe y documenta el ajuste y análisis de un
modelo de regresión lineal simple en base a los datos proporcionados
para una variable explicativa X y una variable respuesta Y.

El estudio se fundamentará en los conceptos teóricos relacionados con
los modelos de regresión lineal simple y su validación que fueron
estudiados a lo largo de los Temas 6 y 7 de la asignatura de Inferencia
Estadística. Se hará referencia explícita a los mismos a medida que sean
empleados.

Asimismo, se utilizará R para realizar las operaciones necesarias para
el análisis. Los detalles relativos al empleo de sus funciones se
detallarán o bien en el propio informe o bien a través de comentarios
sobre el código.

\hypertarget{modelo-de-regresiuxf3n-lineal-simple}{%
\section{Modelo de regresión lineal
simple}\label{modelo-de-regresiuxf3n-lineal-simple}}

Recordemos que un modelo de regresión sirve para representar la
dependencia de una variable Y respecto de una o varias variables X. En
particular, en el modelo de regresión lineal simple se consideran
variables X e Y univariantes (esto es, reflejan el valor de una sola
característica) y parte de las hipótesis de linealidad, homocedasticidad
y normalidad e independencia de los errores (véase una explicación
detallada de las mismas en el ejercicio 7).

Consideraremos una muestra extraída bajo diseño fijo, esto es, con datos
\((x_1, Y_1), ..., (x_n, Y_n)\), donde \(x_1, ..., x_n\) están fijados
por el experimentador.

Así, tendremos \[
Y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i  \quad \text{para}\; i \in {1,...,n}
\] donde \(\epsilon_1,...,\epsilon_n \in N(0, \sigma^2)\) y son
independientes.

Este modelo presenta 3 parámetros: \(\beta_0\), el valor inicial de la
media de la variable respuesta cuando X es 0 (es decir, la ordenada en
el origen de la recta); \(\beta_1\), la cantidad en la que crece dicha
media cada vez que X se incrementa en una unidad (la pendiente); y
\(\sigma^2\), la varianza del error (por hipótesis de homocedasticidad,
toma un valor fijo para cualquier valor x de la variable explicativa).

\hypertarget{cuestiones-preliminares}{%
\section{Cuestiones preliminares}\label{cuestiones-preliminares}}

En cada una de las secciones del documento se trabajará con
\textbf{$\alpha = 0.01$} para los distintos contrastes, intervalos de
confianza, etc. planteados. Equivalentemente, se empleará un nivel de
significación \(1 - \alpha = 0.99\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alfa }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.99}\NormalTok{; alfa}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf.level }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alfa; conf.level}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.99
\end{verbatim}

Esta elección se debe al enunciado del tercer ejercicios, dónde se pide
emplear un nivel de significación del 99\% para la construcción de
intervalos de confianza de los parámetros del modelo. Para mantener
entonces la consistencia en todo el informe, se decidió conservarlo en
los demás apartados que lo requieren.

\hypertarget{libreruxedas-utilizadas}{%
\subsection{Librerías utilizadas}\label{libreruxedas-utilizadas}}

Cargamos a continuación todas las librerías que utilizaremos a lo largo
de la ejecución. Si alguno de los paquetes no ha sido previamente
instalado, debe ejecutarse la instrucción
\textbackslash texttt\{\_install.packages(``nombre\_del\_paquete'')\}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("paquete\_de\_ejemplo")}
\FunctionTok{library}\NormalTok{(ggplot2)      }\CommentTok{\# Para diagrama de dispersión con región de confianza}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'ggplot2' was built under R version 4.1.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpanel)       }\CommentTok{\# Controles adicionales en sm.regression}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'rpanel' was built under R version 4.1.3
\end{verbatim}

\begin{verbatim}
## Loading required package: tcltk
\end{verbatim}

\begin{verbatim}
## Package `rpanel', version 1.1-5: type help(rpanel) for summary information
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(viridis)      }\CommentTok{\# Gradiente de colores en el histograma}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'viridis' was built under R version 4.1.3
\end{verbatim}

\begin{verbatim}
## Loading required package: viridisLite
\end{verbatim}

\begin{verbatim}
## Warning: package 'viridisLite' was built under R version 4.1.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(nortest)      }\CommentTok{\# Necesario para lillie.test}
\FunctionTok{library}\NormalTok{(car)          }\CommentTok{\# Necesario para QQPlot}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: carData
\end{verbatim}

\begin{verbatim}
## Warning: package 'carData' was built under R version 4.1.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sm)           }\CommentTok{\# Contraste no paramétrico de linealidad}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'sm' was built under R version 4.1.3
\end{verbatim}

\begin{verbatim}
## Package 'sm', version 2.2-5.7: type help(sm) for summary information
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lmtest)       }\CommentTok{\# Test de Harrison{-}McCabe (contraste de homocedasticidad)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'lmtest' was built under R version 4.1.3
\end{verbatim}

\begin{verbatim}
## Loading required package: zoo
\end{verbatim}

\begin{verbatim}
## Warning: package 'zoo' was built under R version 4.1.3
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'zoo'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     as.Date, as.Date.numeric
\end{verbatim}

\hypertarget{lectura-de-datos}{%
\subsection{Lectura de datos}\label{lectura-de-datos}}

En primer lugar, leemos los datos del archivo proporcionado, que cuenta
con 76 variables respuesta, Y1, \ldots, Y76, y una variable explicativa
común, X. En nuestro caso, limitaremos el estudio a Y47, que denotaremos
sencillamente como Y de aquí en adelante.

Nada más importar el archivo (para lo cual es necesario que el usuario
cambie el directorio actual, empleando, por ejemplo, \emph{setwd} o
\emph{Ctrl + May + H}), realizamos un pequeño análisis estadístico de
los datos empleando las funciones estándar \emph{head}, \emph{class},
\emph{names}, \emph{str} y \emph{summary}.

Por comodidad para cálculos posteriores, también guardamos el número de
datos, n.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) \# Configurar wd a la carpeta actual (solo en RStudio) }
\CommentTok{\# Ejemplo de uso de setwd para cambiar el directorio actual:}
\CommentTok{\#setwd("C:\textbackslash{}\textbackslash{}Users\textbackslash{}\textbackslash{}Pablo\textbackslash{}\textbackslash{}Desktop\textbackslash{}\textbackslash{}IE\_Regresion")}

\CommentTok{\# Leemos los datos empleando read.table (por la extensión .txt)}
\CommentTok{\# Indicamos que existe una cabecera, que las columnas están separadas por espacios y que el signo decimal es el punto.}
\NormalTok{datos }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"datos\_trabajo\_temas6y7.txt"}\NormalTok{, }\AttributeTok{header=}\NormalTok{T, }\AttributeTok{sep=}\StringTok{" "}\NormalTok{, }\AttributeTok{dec=}\StringTok{"."}\NormalTok{)}
\CommentTok{\# Vemos los nombres de las variables}
\FunctionTok{names}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Y1"  "Y2"  "Y3"  "Y4"  "Y5"  "Y6"  "Y7"  "Y8"  "Y9"  "Y10" "Y11" "Y12"
## [13] "Y13" "Y14" "Y15" "Y16" "Y17" "Y18" "Y19" "Y20" "Y21" "Y22" "Y23" "Y24"
## [25] "Y25" "Y26" "Y27" "Y28" "Y29" "Y30" "Y31" "Y32" "Y33" "Y34" "Y35" "Y36"
## [37] "Y37" "Y38" "Y39" "Y40" "Y41" "Y42" "Y43" "Y44" "Y45" "Y46" "Y47" "Y48"
## [49] "Y49" "Y50" "Y51" "Y52" "Y53" "Y54" "Y55" "Y56" "Y57" "Y58" "Y59" "Y60"
## [61] "Y61" "Y62" "Y63" "Y64" "Y65" "Y66" "Y67" "Y68" "Y69" "Y70" "Y71" "Y72"
## [73] "Y73" "Y74" "Y75" "Y76" "X"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Y nos quedamos con las variables de interés}
\NormalTok{datos }\OtherTok{\textless{}{-}}\NormalTok{ datos[, }\FunctionTok{c}\NormalTok{(}\StringTok{"X"}\NormalTok{, }\StringTok{"Y47"}\NormalTok{)]}

\CommentTok{\# Comprobamos la estructura de las primeras filas}
\FunctionTok{head}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        X     Y47
## 1 1.1370  1.4567
## 2 6.2230 -1.2109
## 3 6.0927 -2.1529
## 4 6.2338 -2.1343
## 5 8.6092 -4.9584
## 6 6.4031 -1.3663
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comprobamos que el objeto resultante es un data.frame}
\FunctionTok{class}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "data.frame"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comprobamos la estructura de los datos}
\FunctionTok{str}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    120 obs. of  2 variables:
##  $ X  : num  1.14 6.22 6.09 6.23 8.61 ...
##  $ Y47: num  1.46 -1.21 -2.15 -2.13 -4.96 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Seleccionamos las dos variables de interés}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ datos[,}\StringTok{"X"}\NormalTok{]}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ datos[,}\StringTok{"Y47"}\NormalTok{]}

\CommentTok{\# Y realizamos un pequeño análisis estadístico exploratorio}
\FunctionTok{summary}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        X              Y47         
##  Min.   :0.095   Min.   :-7.0839  
##  1st Qu.:1.795   1st Qu.:-2.4687  
##  Median :3.232   Median : 0.1661  
##  Mean   :4.268   Mean   :-0.1815  
##  3rd Qu.:6.667   3rd Qu.: 2.3278  
##  Max.   :9.921   Max.   : 5.9654
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))     }\CommentTok{\# Gráficos dispuestos en 1 fila con 2 columnas}
\FunctionTok{hist}\NormalTok{(Y, }\AttributeTok{col=}\FunctionTok{viridis}\NormalTok{(}\DecValTok{7}\NormalTok{), }\AttributeTok{main=}\StringTok{"Histograma de la variable respuesta"}\NormalTok{)}
\FunctionTok{rug}\NormalTok{(Y)}
\FunctionTok{boxplot}\NormalTok{(Y, }\AttributeTok{col=}\StringTok{"gray"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Diagrama de caja de la variable respuesta"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/cars-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))     }\CommentTok{\# Reiniciamos al valor predeterminado para las ventanas gráficas}



\CommentTok{\# Guardamos el número de datos}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\hypertarget{relaciuxf3n-entre-variable-explicativa-y-variable-respuesta}{%
\section{1) Relación entre variable explicativa y variable
respuesta}\label{relaciuxf3n-entre-variable-explicativa-y-variable-respuesta}}

En primer lugar, calculamos la covarianza y el coeficiente de
correlación entre las variables: \[
S_{xY}=\frac{1}{n}\sum_{i=1}^n (x_i-\overline{x})(Y_i-\overline{Y}))\quad\quad\quad 
r_{xY}=\frac{S_{xY]}}{\sqrt{S_x^2}\sqrt{S_Y^2}}
\]

Debemos tener en cuenta que R calcula la covarianza como una
'cuasi'covarianza, es decir, dividiendo entre \(n-1\) en lugar de entre
\(n\). Para corregirlo, multiplicamos por \(n-1\) y dividimos entre
\(n\), aunque también mostraremos el valor original. No afectará al
coeficiente de correlación, pues el denominador se anula con los
\(\sqrt{n-1}\) de las cuasidesviaciones típicas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covar }\OtherTok{=} \FunctionTok{cov}\NormalTok{(X,Y) }\SpecialCharTok{*}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n; covar     }\CommentTok{\# Covarianza}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -8.275695
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cov}\NormalTok{(X, Y)                                 }\CommentTok{\# Cuasicovarianza}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -8.345238
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(X, Y)                                 }\CommentTok{\# Coeficiente de correlación}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.9506962
\end{verbatim}

Que la covarianza sea distinta de 0 nos indica que hay una relación
lineal. Además, al ser negativa, deducimos que esta es
indirecta/inversa, es decir, que al aumentar la variable X, la variable
Y diminuye.

Adionalmente, ya sabemos que la recta de regresión que obtendremos
posteriormente será decreciente, pues la pendiente estimada,
\(\beta_1 = \frac{S_{xY}}{S_x^2}\), tiene el mismo signo que \(S_{xY}\),
al ser la varianza siempre no negativa, y hemos obtenido que
\(S_{xY} < 0\).

Por un razonamiento análogo, \(r_{xY}\) también debe tener el mismo
signo que \(S_{xY}\) y, en efecto, esto es lo que observamos en los
resultados. La interpretación de su signo es, por tanto, la misma que la
expuesta para la covarianza (relación lineal inversa/indirecta).

Ahora bien, no podemos sacar conclusiones acerca de la magnitud de la
covarianza, pues esta tiene unidades (que ni siquiera conocemos). Por el
contrario, el coeficiente de correlación es adimensional y, de hecho,
sabemos que \(|r_{xY}| \in [-1,1]\). Como \(|r_{xY}| > 0.75\), la
relación entre las variables es fuerte, esto es, tienen una correlación
significativa. Cuando representemos el diagrama de dispersión de los
datos y sobre el mismo, la recta de regresión, observaremos que los
puntos son próximos a esta.

\hypertarget{representaciuxf3n-gruxe1fica}{%
\subsubsection{Representación
gráfica}\label{representaciuxf3n-gruxe1fica}}

Para visualizar la relación entre la variable explicativa y la variable
respuesta, emplearemos un diagrama de dispersión.

En primer lugar, hallamos el vector de medias o centro de gravedad
aplicando \texttt{mean} en ambas variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mX }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(X)}
\NormalTok{mY }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y)}

\FunctionTok{c}\NormalTok{(mX, mY) }\CommentTok{\# Mostramos el vector de medias}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.2681600 -0.1815108
\end{verbatim}

Como diagrama básico, emplearemos la función \texttt{plot}. Como
recurriremos a este gráfico en particular en varias ocasiones a lo largo
de este documento, vamos a definir una función que englobe la
representación:

\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/dispersion-1.pdf}

Se puede ver que la nube de puntos toma una forma descendente, lo cual
es coherente con la correlación negativa de X e Y. También vemos que los
datos están, de forma aproximada, uniformemente alineados en torno a una
forma rectilínea. Todo esto motiva el establecimiento de un modelo
lineal para la relación entre ambas variables que, recordemos, son de la
forma: \[
Y = \beta_0 + \beta_1X + \epsilon
\]

Ajustamos entonces este modelo a nuestros datos mediante la función
\texttt{lm}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Y}\SpecialCharTok{\textasciitilde{}}\NormalTok{X); modelo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Y ~ X)
## 
## Coefficients:
## (Intercept)            X  
##       4.184       -1.023
\end{verbatim}

y obtenemos un intercepto \(\beta_0 = 4.184\) y una pendiente de
\(\beta_1 = -1.023\), lo cual concuerda con lo observado anteriormente
en la nube de puntos.

En los siguientes ejercicios, analizaremos en profundidad diferentes
caracteríssticas de este modelo y obtendremos inferencia a partir del
mismo. Nótese que para que las conclusiones extraídas en estos
ejercicios tengan validez, deberemos suponer que se cumplen las
hipótesis de linealidad, homocedasticidad y normalidad e independencia
de los errores. Las comprobaremos de forma precisa en el ejercicio 7,
pero de no ser válida alguna de ellas, tendríamos que revisar y
descartar multitud de resultados.

\hypertarget{estimaciones-puntuales-de-los-paruxe1metros-y-representaciuxf3n-del-modelo}{%
\subsection{2) Estimaciones puntuales de los parámetros y representación
del
modelo}\label{estimaciones-puntuales-de-los-paruxe1metros-y-representaciuxf3n-del-modelo}}

Para la estimación puntual de los parámetros intercepto \(\beta_0\),
pendiente \(beta_1\) y para la de la varianza del error \(\sigma^2\)
podemos aplicar directamente las fórmulas obtenidas en la parte teórica
de la asignatura:

\begin{gather*}
\hat{\beta_0} = \frac{\overline{Y}} - \frac{S_{xY}}{s^2_x}\overline{x}
\hat{\beta_1} = \frac{S_{xY}}{s^2_x}
\hat{\sigma^2} = \frac{1}{n-2} \cdot \sum_{1}^{n} (Y_i - \hat{\beta_0} - \hat{\beta_1}x_i)^2
\end{gather*}

Veamos a través de R cuáles son sus valores:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var.X }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(X)}\SpecialCharTok{*}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{n           }\CommentTok{\# Obtenemos la varianza multiplicando la cuasivarianza por (n{-}1)/n}
\NormalTok{beta0.gorro }\OtherTok{\textless{}{-}}\NormalTok{ mY }\SpecialCharTok{{-}}\NormalTok{ covar}\SpecialCharTok{*}\NormalTok{mX}\SpecialCharTok{/}\NormalTok{var.X; beta0.gorro}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.184343
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta1.gorro }\OtherTok{\textless{}{-}}\NormalTok{ covar}\SpecialCharTok{/}\NormalTok{var.X; beta1.gorro}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1.022889
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var.error }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((Y }\SpecialCharTok{{-}}\NormalTok{ beta0.gorro }\SpecialCharTok{{-}}\NormalTok{ beta1.gorro}\SpecialCharTok{*}\NormalTok{X)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(n}\DecValTok{{-}2}\NormalTok{); var.error}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.916048
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd.error }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(var.error); sd.error      }\CommentTok{\# Vemos también el valor estimado de la desviación típica del error}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.957104
\end{verbatim}

De manera alternativa, podemos obtenerlas a partir del propio modelo
creado anteriomente por R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Y ~ X)
## 
## Coefficients:
## (Intercept)            X  
##       4.184       -1.023
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Intercepto beta0gorro y pendiente beta1gorro}
\NormalTok{modelo}\SpecialCharTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)           X 
##    4.184343   -1.022889
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Varianza del error}
\FunctionTok{sum}\NormalTok{(modelo}\SpecialCharTok{$}\NormalTok{residuals}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.916048
\end{verbatim}

En el código anterior hemos utilizado
\textbackslash texttt\{modelo\$residuals\} para obtener los residuos del
modelo (los errores de predicción): \[
\hat\epsilon_i = Y_i - \hat\beta_0 - \hat\beta_1x_i \quad \text{para} \; i \in {1,...,n},
\] así como la expresión alternativa de la varianza del error: \[
\hat{\sigma^2} = \frac{1}{n-2} \cdot \sum_{1}^{n} \hat\epsilon_i^2
\]

Vemos que nuestros cálculos coinciden con los obtenidos por R, ya que
las fórmulas empleadas son las mismas.

A continuación, en base a la representación definida anteriormente,
añadimos la recta de regresión ajustada del modelo:
\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/dispersionReg-1.pdf}

Incluimos también una gráfica adicional usando la librería
\emph{ggplot2} e incluyendo la región o intervalo de confianza para los
datos al nivel fijado del 99\%:
\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/dispersionRegGGPLOT-1.pdf}

\hypertarget{intervalos-de-confianza-de-los-paruxe1metros-del-modelo}{%
\subsection{3) Intervalos de confianza de los parámetros del
modelo}\label{intervalos-de-confianza-de-los-paruxe1metros-del-modelo}}

A continuación, hallamos sendos intervalos de confianza para
\(\beta_0\), \(\beta_1\) y \(\sigma^2\). Todos estos se harán para el
nivel de significación \(\alpha = 0.01\) definido previamente.

\hypertarget{beta_0}{%
\subsubsection{\texorpdfstring{\(\beta_0\)}{\textbackslash beta\_0}}\label{beta_0}}

El pivote que emplearemos para esta estimación será \[
\frac{\hat\beta_0 - beta0}{\hat\sigma\sqrt{\frac{1}{n}+\frac{\overline{x}^2}{nS_x^2}}} \in T_{n_2}
\] de modo que el intervalo de confianza será: \[
(\hat\beta_0-t_{n-2,\frac{\alpha}{2}} \hat\sigma \sqrt{\frac{1}{n} +\frac{\overline{x}^2}{nS_x^2}}, \hat\beta_0+t_{n-2,\frac{\alpha}{2}} \hat\sigma \sqrt{\frac{1}{n} +\frac{\overline{x}^2}{nS_x^2}})
\] dónde \(t_{n-2,\frac{\alpha}{2}}\) es el cuantil
\(1-\frac{\alpha}{2} = 0.995\) de una T de Student con \(n-2= 118\)
grados de libertad.

En primer lugar, obtengamos el intervalo de confianza a mano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta0.cuantil }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{alfa}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df=}\NormalTok{n}\DecValTok{{-}2}\NormalTok{); beta0.cuantil       }\CommentTok{\# Cuantil 1{-}alfa/2 de T de Student con n{-}2 grados de libertad}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.618137
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta0.extremoinferior }\OtherTok{\textless{}{-}}\NormalTok{ beta0.gorro }\SpecialCharTok{{-}}\NormalTok{ beta0.cuantil }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(var.error }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{n }\SpecialCharTok{+}\NormalTok{ mX}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{var.X)))}
\NormalTok{beta0.extremosuperior }\OtherTok{\textless{}{-}}\NormalTok{ beta0.gorro }\SpecialCharTok{+}\NormalTok{ beta0.cuantil }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(var.error }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{n }\SpecialCharTok{+}\NormalTok{ mX}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{var.X)))}
\NormalTok{beta0.IC }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(beta0.extremoinferior, beta0.extremosuperior); beta0.IC      }\CommentTok{\# Intervalo de confianza}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.771852 4.596833
\end{verbatim}

Interpretamos que, en base a los datos de esta muestra, el intervalo
\((3.771852, 4.596833)\) contendrá al parámetro \(\beta_0\) con una
probabilidad del 99\%.

\hypertarget{beta_1}{%
\subsubsection{\texorpdfstring{\(\beta_1\)}{\textbackslash beta\_1}}\label{beta_1}}

Para el intervalo de confianza de la pendiente, usaremos ahora el pivote
\[
\frac{\hat{\beta_1} - \beta_1}{\hat\sigma / {S_x \sqrt{n}}} \in T_{n-2}
\]

a partir del cuál obtenemos el intervalo: \[
(\hat\beta_1 - t_{n-2, \frac{\alpha}{2}}\frac{\hat{\sigma}}{S_x \sqrt{n}}, \hat\beta_1 + t_{n-2, \frac{\alpha}{2}}\frac{\hat\sigma}{S_x \sqrt{n}})
\]

donde de nuevo \(t_{n-2,\frac{\alpha}{2}}\) es el cuantil
\(1-\frac{\alpha}{2} = 0.995\) de una T de Student con \(n-2= 118\)
grados de libertad.

De nuevo, obtenemos el intervalo a mano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta1.cuantil }\OtherTok{\textless{}{-}}\NormalTok{ beta0.cuantil      }\CommentTok{\# Empleamos el mismo cuantil, dado que fijamos el mismo alfa}
\NormalTok{beta1.extremoinferior }\OtherTok{\textless{}{-}}\NormalTok{ beta1.gorro }\SpecialCharTok{{-}}\NormalTok{ beta1.cuantil }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(var.error }\SpecialCharTok{/}\NormalTok{ (var.X }\SpecialCharTok{*}\NormalTok{ n))}
\NormalTok{beta1.extremosuperior }\OtherTok{\textless{}{-}}\NormalTok{ beta1.gorro }\SpecialCharTok{+}\NormalTok{ beta1.cuantil }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(var.error }\SpecialCharTok{/}\NormalTok{ (var.X }\SpecialCharTok{*}\NormalTok{ n))}
\NormalTok{beta1.IC }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(beta1.extremoinferior, beta1.extremosuperior); beta1.IC   }\CommentTok{\# Mostramos el intervalo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1.1033105 -0.9424673
\end{verbatim}

Interpretamos así que, en base a los datos de esta muestra, el intervalo
\((-1.1033105, -0.9424673)\) contendrá al parámetro \(\beta_1\) con una
probabilidad del 99\%. -1.1033105 -0.9424673

\hypertarget{sigma2}{%
\subsubsection{\texorpdfstring{\(\sigma^2\)}{\textbackslash sigma\^{}2}}\label{sigma2}}

Por último, para el intervalo de confianza de la varianza del error,
usaremos

\[
\frac{(n-2)\hat{sigma^2}}{\sigma^2} \in \chi^2_{n-2}
\] de dónde obtenemos el intervalo: \[
(\frac{(n-2)\hat{\sigma^2}}{\chi^2_{n-2, \frac{\alpha}{2}}}, \frac{(n-2)\hat{\sigma^2}}{\chi^2_{n-2, 1-\frac{\alpha}{2}}})
\]

donde \(\chi^2_{n-2, \frac{\alpha}{2}}\) es el cuantil
\(1-\frac{\alpha}{2}=0.995\) de una \(\chi^2\) con \(n-2=118\) grados de
libertad, y \(\chi^2_{n-2, 1-\frac{\alpha}{2}}\) es el cuantil
\(\frac{\alpha}{2}=0.005\) de una \(\chi^2\) con \(n-2=118\) grados de
libertad.

Calculamos entonces este intervalo a mano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var.error.cuantilinferior }\OtherTok{\textless{}{-}} \FunctionTok{qchisq}\NormalTok{(alfa}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ n}\DecValTok{{-}2}\NormalTok{)       }\CommentTok{\# Cuantil alfa/2 de chi{-}cuadrado con n{-}2 grados de libertad}
\NormalTok{var.error.cuantilsuperior }\OtherTok{\textless{}{-}} \FunctionTok{qchisq}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{alfa}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ n}\DecValTok{{-}2}\NormalTok{)     }\CommentTok{\# Cuantil 1{-}alfa/2}
\NormalTok{var.error.extremoinferior }\OtherTok{\textless{}{-}}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ var.error}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ var.error.cuantilsuperior}
\NormalTok{var.error.extremosuperior }\OtherTok{\textless{}{-}}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ var.error}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ var.error.cuantilinferior}
\NormalTok{var.error.IC }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(var.error.extremoinferior, var.error.extremosuperior); var.error.IC     }\CommentTok{\# Intervalo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6138273 1.2048240
\end{verbatim}

Interpretamos así que, en base a los datos de esta muestra, el intervalo
\((0.6138273, 1.2048240)\) contendrá al parámetro \(\sigma^2\) con una
probabilidad del 99\%.

Pero también podemos utilizar las funciones de R para calcular los
intervalos de confianza para \(\beta_0\) y \(\beta_1\) de forma
automática:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Intervalo de confianza para la ordenada en el origen y la pendiente con nivel del 99\% en base al modelo construido}
\FunctionTok{confint}\NormalTok{(modelo, }\AttributeTok{level =} \FloatTok{0.99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 0.5 %     99.5 %
## (Intercept)  3.771852  4.5968334
## X           -1.103311 -0.9424673
\end{verbatim}

Vemos que los valores obtenidos coinciden con los extremos del intervalo
que calculábamos anteriormente, pues R emplea la misma construcción que
hemos visto de forma teórica.

No hay ninguna función estándar para la automatización del intervalo de
confianza para la varianza del error.

\hypertarget{contrastes-de-significaciuxf3n-asociados-al-intercepto-y-a-la-pendiente}{%
\subsection{4) Contrastes de significación asociados al intercepto y a
la
pendiente}\label{contrastes-de-significaciuxf3n-asociados-al-intercepto-y-a-la-pendiente}}

\textit{Realiza los contrates de significación asociados al intercepto y a la pendiente del modelo de regresión considerado. Interpreta los resultados obtenidos. En base a los resultados obtenidos, ¿tendría sentido considerar otro modelo más sencillo?}

A continuación, realizaremos los contrastes de significación sobre los
parámetros \(\hat{\beta_0} y \hat{\beta_1}\) con el objetivo de
determinar si el modelo se podría simplificar a uno con menos variables
o no. Las hipótesis de estos contrastes son, respectivamente: \[
\begin{cases}
H_0: \beta_0 = 0\\
H_a: \beta_0 \neq 0
\end{cases}
\] y \[
\begin{cases}
H_0: \beta_1 = 0\\
H_a: \beta_1 \neq 0
\end{cases}
\]

Si no consiguiéramos demostrar la hipótesis alternativa para el primer
contraste, tendríamos que considerar un modelo más sencillo, que no solo
facilitaría el análisis estadístico, sino que es más correcto y realista
de cara a las interpretaciones que podamos hacer. En el caso del segundo
contraste, no demostrar la hipótesis alternativa equivaldría a invalidar
nuestro modelo, pues significaría que no hay regresión.

En primer lugar, calculamos los contrastes de forma manual. Esto se hará
a partir de los estadísticos de contraste basados en los pivotes
empleados para obtener los intervalos de confianza del ejercicio 3,
teniendo en cuenta que, bajo las respectivas hipótesis nulas,
\(\beta_0 = 0\) y \(\beta_1 = 0\):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cálculo de los valores de los estadísticos de contraste para beta0 y beta1 bajo H0}
\NormalTok{beta0.t }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(beta0.gorro) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(var.error }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ n }\SpecialCharTok{+}\NormalTok{ mX }\SpecialCharTok{\^{}} \DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*}\NormalTok{ var.X)))); beta0.t}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.55861
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta1.t }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(beta1.gorro) }\SpecialCharTok{/}\NormalTok{ (sd.error }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ var.X)); beta1.t}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 33.30029
\end{verbatim}

DEFINIR LA REGIÓN DE RECHAZO -\_-

\hypertarget{ambos-contrastes-caen-en-la-regiuxf3n-de-rechazo}{%
\section{Ambos contrastes caen en la región de
rechazo}\label{ambos-contrastes-caen-en-la-regiuxf3n-de-rechazo}}

beta0.t \textgreater{} beta0.cuantil beta1.t \textgreater{}
beta1.cuantil

\hypertarget{calculo-de-p-valores}{%
\section{Calculo de p-valores}\label{calculo-de-p-valores}}

beta0.pvalor \textless- dt(beta0.t, df = n-2); beta0.pvalor beta1.pvalor
\textless- dt(beta1.t, df = n-2); beta1.pvalor

\begin{verbatim}
Habiendo fijado previamente el nivel de significación $\alpha = 0.01$, llegamos en ambos casos a que noe existen evidencias estadísticamente significativas a favor de $H_a$. Es decir, no tenemos pruebas a favor de H_0. Podemos asumir entonces que tanto el intercepto $\beta_0$ como la pendiente $\beta_1$ del modelo serán distintos de 0. En base a esto, lo sensato será no simplificar nuestro modelo y continuar realizando regresión lineal con estos 2 parámetros.

Como vemos, en ambos contrastes el p-valor es prácticamente nulo ($<10^-50$), lo cual nos indica que las pruebas para rechazar la hipótesis nula son estadísticamente significativas para los niveles de significación habituales o incluso con precisiones mucho mayores.

Alternativamente, podemos obtener los valores de estos dos contrastes de significación y su p-valor a partir de los datos presentes en el modelo de R. Para esto, usaremos la función summary:

```r
summary(modelo)
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.76465 -0.72493  0.00685  0.71260  2.20924 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  4.18434    0.15755   26.56   <2e-16 ***
## X           -1.02289    0.03072  -33.30   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9571 on 118 degrees of freedom
## Multiple R-squared:  0.9038, Adjusted R-squared:  0.903 
## F-statistic:  1109 on 1 and 118 DF,  p-value: < 2.2e-16
\end{verbatim}

En concreto, los valores relevantes son el \texttt{t-value} y el
\texttt{Pr(>|t|)} de las filas \texttt{(Intercept)} y \texttt{X} que se
corresponden al valor observado del estadístico de contraste y su
p-valor, para el intercepto \(\beta_0\) y la pendiente \(\beta_1\)
respectivamente.

\hypertarget{intervalos-de-prediciuxf3n-y-confianza-para-la-media-condicionada}{%
\subsection{5) Intervalos de predición y confianza para la media
condicionada}\label{intervalos-de-prediciuxf3n-y-confianza-para-la-media-condicionada}}

\textit{Si consideramos que la variable X toma 3 nuevos valores: 2, 4 y 6 unidades, proporciona intervalos de predicción e intervalos de confianza para la media condicionada de la variable Y. Interpreta los resultados obtenidos.}

En este apartado, consideremos los 3 nuevos valores para la variable
explicativa: \({2, 4, 6}\). Para obtener intervalos de confianza para la
esperanza de Y condicionada a estos valores y de predicción, será
necesario comprobar primero que estos datos están dentro del rango de
observación de X. Esto es necesario ya que no sabemos cómo se comporta
el modelo fuera del rango observado, y nuestro objetivo es en todo
momento predecir y no extrapolar el modelo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nuevosValores }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{nuevosValores}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 4 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Los nuevos valores están contenidos dentro del rango observado}
\FunctionTok{min}\NormalTok{(X) }\SpecialCharTok{\textless{}} \FunctionTok{min}\NormalTok{(nuevosValores) }\SpecialCharTok{\&\&} \FunctionTok{max}\NormalTok{(X) }\SpecialCharTok{\textgreater{}} \FunctionTok{max}\NormalTok{(nuevosValores)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Construimos un data.frame  con los nuevos datos ya que predict necesita ese formato}
\NormalTok{nuevosDatos }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\StringTok{"X"} \OtherTok{=}\NormalTok{ nuevosValores)}
\end{Highlighting}
\end{Shaded}

Habiendo realizado esta comprobación, ya podemos obtener los intervalos
utilizando la función \texttt{predict} sobre el modelo de R. Obtendremos
ambos intervalos para el nivel de significación fijado anteriormente
\(\alpha = 0.99\).

En primer lugar, pasando el argumento
\(\texttt{interval = "confidence"}\), hallamos los intervalos de
confianza asociados a la media condicionada.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ nuevosDatos, }\AttributeTok{interval =} \StringTok{"confidence"}\NormalTok{, }\AttributeTok{level =}\NormalTok{ alfa)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           fit        lwr        upr
## 1  2.13856482  2.1371613  2.1399684
## 2  0.09278705  0.0916848  0.0938893
## 3 -1.95299072 -1.9542755 -1.9517059
\end{verbatim}

Y para obtener los intervalos de predicción, los cuáles serán más
amplios que los anteriores, pasamos el argumento
\(\texttt{interval = "prediction"}\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ nuevosDatos, }\AttributeTok{interval =} \StringTok{"prediction"}\NormalTok{, }\AttributeTok{level =}\NormalTok{ alfa)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           fit         lwr        upr
## 1  2.13856482  2.12646188  2.1506678
## 2  0.09278705  0.08071534  0.1048588
## 3 -1.95299072 -1.96508046 -1.9409010
\end{verbatim}

\hypertarget{ejercicio-6}{%
\subsection{Ejercicio 6}\label{ejercicio-6}}

\textit{Calcula alguna medida de bondad de ajuste del modelo lineal simple considerado.}
El objetivo del cálculo de una medida de bondad de ajuste es determinar
como de ``bueno'' o ``potente'' es un modelo de regresión. En terminos
estadísticos, esto se traduce a cuánta proporción de la variabilidad de
\(Y\) puede ser explicada por el modelo de regresión. Una de las medidas
principales para lograr este objetivo es el
\textit{coeficiente de determinación $R^2$}. En el caso del modelo
lineal, podemos descomponer la varianza como

\[
\sigma_Y^2 = 
\sum_{i=1}^n (Y_i - \overline{Y})^2 = 
\sum_{i=1}^n (Y_i - \hat{\beta_0} - \hat{\beta_1}x_i)^2 + 
\sum_{i=1}^n (\hat{\beta_0} + \hat{\beta_1}\cx_i - \overline{Y})^2
\]

Dónde observamos que el segundo sumando representa la varianza explicada
por la recta de regresión, mientras que el primero representa la no
explicada. Es por tanto necesario que el cociente \(\frac{RSS}{TSS}\),
dónde TSS (\textit{Total Sum of Squares}) es la varianza total de \(Y\)
y RSS (\textit{Residual Sum of Squares}) es la no explicada por el
modelo, sea lo menor posible. Definimos entonces el coeficiente de
determinación \(R^2 = 1 - \frac{RSS}{TSS}\). En primer lugar,
calcularemos este cociente a mano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rss }\OtherTok{=} \FunctionTok{sum}\NormalTok{((Y }\SpecialCharTok{{-}}\NormalTok{ beta0.gorro }\SpecialCharTok{{-}}\NormalTok{ beta1.gorro}\SpecialCharTok{*}\NormalTok{X)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{); rss}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 108.0937
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tss }\OtherTok{=} \FunctionTok{var}\NormalTok{(Y)}
\NormalTok{r2 }\OtherTok{=} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rss}\SpecialCharTok{/}\NormalTok{tss; r2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -10.44502
\end{verbatim}

Aunque también podemos obtenerla a partir del modelo de R, en el campo
\textit{Adjusted R-Squared} del \texttt{summary}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.76465 -0.72493  0.00685  0.71260  2.20924 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  4.18434    0.15755   26.56   <2e-16 ***
## X           -1.02289    0.03072  -33.30   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9571 on 118 degrees of freedom
## Multiple R-squared:  0.9038, Adjusted R-squared:  0.903 
## F-statistic:  1109 on 1 and 118 DF,  p-value: < 2.2e-16
\end{verbatim}

Obtenemos un valor de \(0.903\), lo cuál nos indica que nuestro modelo
es bastante potente en términos habituales. Cabe destacar que el hecho
de que el coeficiente de determinación sea alto, no nos indica aún que
nuestro modelo sea correcto, lo cuál será discutido en el apartado 7. El
recíproco tampoco es cierto, podríamos tener un modelo correcto que no
fuera bueno. Intuitivamente, este valor alto se contrasta con el hecho
de que en el diagrama de dispersión los datos sean cercanos a la recta
de regresión.

\hypertarget{ejercicio-7}{%
\subsection{Ejercicio 7}\label{ejercicio-7}}

\textit{Completa la validación del modelo de regresión lineal simple, contrastando las cuatro hipótesis básicas asociadas al mismo: linealidad, homocedasticidad, normalidad e independencia. Apoya los resultados obtenidos con representaciones gráficas. En base a los resultados obtenidos, ¿qué puedes decir sobre el modelo de regresión considerado?}

Las técnicas de inferencia empleadas hasta el momento son ciertas bajo
el supuesto de que las 4 hipótesis del modelo de regresión lineal simple
(linealidad, homocedasticidad, normalidad e independencia) se verifican.
De lo contrario, no todas las interpretaciones obtenidas seguirían
siendo válidas. Por ejemplo, si no se cumplieran las hipótesis de
homocedasticidad, normalidad e independencia, los intervalos de
confianza que hemos obtenido no serían válidos.

Bastaría que fallara una de las cuatro hipótesis para afirmar que el
modelo de regresión lineal simple no es un buen modelo para la muestra
de datos.

\hypertarget{linealidad}{%
\subsubsection{Linealidad}\label{linealidad}}

En primer lugar, podemos tratar de aventurar si se los datos siguen una
tendencia lineal. Emplearemos una aproximación exploratoria, a través de
una interpretación gráfica. Para ello, revisitemos la representación
previamente definida.

\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/dispersion2-1.pdf}

Vemos que los puntos parecen distribuirse en torno a la recta de forma
lineal. Si bien hay datos un tanto atípicos, especialmente en los
extremos, esto no es lo suficientemente significativo como para rechazar
la hipótesis. Tampoco se ve un patrón evidente en los datos (es esto lo
que debemos tratar de detectar, y no solo corroborar que haya el mismo
número de puntos por encima/debajo de la recta, que no es suficiente
como para indicar linealidad).

Nótese que aunque se puede apreciar una menor concentración de puntos
para valores de X comprendidos alrededor del valor 4, esto no es
indicativo de una falta de linealidad. Dado que trabajamos bajo diseño
fijo, se tiene que achacar a decisiones sobre las condiciones de
medición o al propio diseño del experimento. Esta observación se puede
comprobar a través del siguiente cuadro:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Representamos el número de valores de X en cada intervalo de longitud 0.5, comenzando desde el mayor entero menor}
\CommentTok{\# o igual que el dato mínimo, y finalizando en el menor entero mayor o igual que el dato máximo.}
\FunctionTok{table}\NormalTok{(}\FunctionTok{cut}\NormalTok{(X, }\AttributeTok{breaks=}\FunctionTok{seq}\NormalTok{(}\AttributeTok{from=}\FunctionTok{floor}\NormalTok{(}\FunctionTok{min}\NormalTok{(X)), }\AttributeTok{to=}\FunctionTok{ceiling}\NormalTok{(}\FunctionTok{max}\NormalTok{(X)), }\AttributeTok{by=}\FloatTok{0.5}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  (0,0.5]  (0.5,1]  (1,1.5]  (1.5,2]  (2,2.5]  (2.5,3]  (3,3.5]  (3.5,4] 
##        9        4       11        9        8        8       13        2 
##  (4,4.5]  (4.5,5]  (5,5.5]  (5.5,6]  (6,6.5]  (6.5,7]  (7,7.5]  (7.5,8] 
##        1        4       11        3        6        4        4        5 
##  (8,8.5]  (8.5,9]  (9,9.5] (9.5,10] 
##        5        5        6        2
\end{verbatim}

Con el objetivo de realizar una prueba más precisa, planteamos el
siguiente contraste de hipótesis. Como hipótesis nula tenemos que la
variable respuesta siga el modelo lineal simple que hemos estado
considerando, y como hipótesis nula, que siga un modelo parabólico,
donde hay dependencia de la variable explicativa al cuadrado: \[
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=\beta_0+\beta_1X+\beta_2\cdotX^2\epsilon
\end{cases}
\]

Ejecutamos la prueba:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Empleamos power = 2 porque estamos considerando una alternativa cuadrática}
\FunctionTok{resettest}\NormalTok{(modelo, }\AttributeTok{power =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  RESET test
## 
## data:  modelo
## RESET = 0.09269, df1 = 1, df2 = 117, p-value = 0.7613
\end{verbatim}

Vemos que el p-valor es de 0.7613. Dado que es superior a nuestro
\(\alpha\) fijado, que era del 0.01, no existen evidencias
estadísticamente significativas a favor de \(H_a\) (de hecho, el p-valor
es superior a cualquiera de los niveles de significación habituales:
1\%, 5\% y 10\%). Es decir, no tenemos pruebas en contra de \(H_0\).
Podemos asumir que la hipótesis nula es cierta: la variable respuesta se
ajusta mejor a un modelo de regresión lineal simple que a uno
cuadrático.

No obstante, este contraste solo nos ha aportado información sobre la
equiparación con un modelo cuadrático. Podríamos plantearlo también para
un modelo cúbico:

\[
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=\beta_0+\beta_1X+\beta_2X^2+\beta_3X^3\epsilon
\end{cases}
\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Empleamos power = 3 porque estamos considerando una alternativa cúbica}
\FunctionTok{resettest}\NormalTok{(modelo, }\AttributeTok{power =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  RESET test
## 
## data:  modelo
## RESET = 0.11319, df1 = 1, df2 = 117, p-value = 0.7371
\end{verbatim}

Como el p-valor es también superior a 0.01, de nuevo podemos aceptar la
hipótesis nula de que el modelo lineal es válido.

\begin{verbatim}
    RESET test
\end{verbatim}

data: modelo RESET = 0.11319, df1 = 1, df2 = 117, p-value = 0.7371

Ahora bien, tendríamos que seguir experimentando para cualquier valores
de power para contraponer estos modelos polinómicos, uno a uno, contra
el lineal simple, pero ni siquiera en este caso estaríamos considerando
todas las opciones de modelos. Dado que una exploración perfecta en este
sentido es impracticable experimentalmente, podemos plantearnos en su
lugar un contraste más general, con una alternativa no parámetrica: \[
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=m(X)+\epsilon
\end{cases}
\]

Haciendo uso del paquete \texttt{sm}, realizamos la prueba de hipótesis:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Importamos rpanel para abrir un panel interactivo para la representación}
\CommentTok{\# Los valores que sabemos interpretar son los que aparecen con las opciones por defecto}
\CommentTok{\# Indicamos test=T para que se nos muestre un p{-}valor.}
\FunctionTok{sm.regression}\NormalTok{(X, Y, }\AttributeTok{model=}\StringTok{"linear"}\NormalTok{, }\AttributeTok{panel=}\NormalTok{T, }\AttributeTok{test=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/smregresion-1.pdf}

La interpretación de la figura resultante es la siguiente. Con una línea
negra nos aparece marcada una estimación no paramétrica de la regresión
(sin asumir linealidad), y en azul, una región de confianza para el
modelo lineal simple. Vemos que la línea negra se encuentra siempre
dentro de la región azul. Por tanto, podemos asumir que la hipótesis
nula es cierta, esto es, que los datos verifican la hipótesis de
linealidad.

Al indicar test=T, hemos obtenido también un p-valor asociado. Como
\(0.659 > 0.01\), de nuevo no tenemos evidencias estadísticamente
significativas a favor de \(H_a\). Equivalentemente, no tenemos pruebas
en contra de \(H_0\). Podemos asumir que la hipótesis nula (que la
variable respuesta se ajuste a un modelo de regresión lineal simple) es
cierta.

\hypertarget{homocedasticidad}{%
\subsubsection{Homocedasticidad}\label{homocedasticidad}}

Corroboraremos ahora que la varianza del error es fija e independiente
del valor que toma la variable explicativa: \[
Var(\epsilon | X = x) = \sigma^2 \quad para todo x.
\]

Contrapongamos ahora los residuos del modelo a la variable explicativa.
Se muestra también el diagrama de dispersión original:
\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/dispersionresiduos-1.pdf}

Vemos que la distribución de los residuos en el diagrama no sigue un
patrón evidente, y que su desviación con respecto a la recta \(x=0\)
parece ser la misma sin importar el intervalo de X considerado.

Tampoco sobre el diagrama de dispersión de la variable respuesta
observamos una tendencia significativa acera de las desviaciones con la
recta de regresión. En conjunción con lo anterior, podríamos aventurar,
a primera vista, que los datos muestrales son verdaderamente
homocedásticos.

Sí destacamos que la interpretación para la región central, en
aproximadamente \((4, 4.5)\), puede no ser muy precisa, por falta de
datos. Sin embargo, esto no basta para desmentir la hipótesis de
homocedasticidad.

Para tener una confirmación precisa, nos planteamos el siguiente
contraste de hipótesis: \[
\begin{cases}
H_0: \text{modelo homocedástico}\\
H_a: \text{modelo heterocedástico}
\end{cases}
\]

Ejecutamos un test de Harrison-McCabe con R, haciendo uso del
previamente cargado paquete \texttt{lmtest}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hmctest}\NormalTok{(Y}\SpecialCharTok{\textasciitilde{}}\NormalTok{X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Harrison-McCabe test
## 
## data:  Y ~ X
## HMC = 0.55113, p-value = 0.802
\end{verbatim}

El p-valor es de \(0.763 > 0.01 = \alpha\). Por un razonamiento análogo
a los anteriores, no existen pruebas estadísticamente significativas
para rechazar la hipótesis nula, y podemos asumirla como válida:
aceptamos que el modelo es homocedástico.

\hypertarget{normalidad}{%
\subsubsection{Normalidad}\label{normalidad}}

Para corroborar que el error tiene distribución normal, haremos varias
representaciones gráficas que nos permitan intuir si la hipótesis se
ajusta a los datos. Trabajaremos con los residuos estandarizados, pues
no tienen la misma varianza y la correlación entre cada 2 de ellos puede
ser distinta (provienen de distribuciones diferentes).

Presentamos 3 gráficos: un histograma, un boxplot y un qqplot (para el
cual necesitamos la librería \texttr{car}), aunque centraremos nuestra
atención en el último de ellos, el más relevante en lo que concierne al
estudio de la normalidad.

\includegraphics{PabloDiazVinambres-XianaCarreraAlonso_files/figure-latex/representacionnormalidad-1.pdf}

\begin{verbatim}
## [1] 93 45
\end{verbatim}

En el histograma podemos apreciar una cierta asimetría hacia la derecha
(valores más altos). En el boxplot o diagrama de caja vemos que la media
está centrada en el centro de la caja, un buen indicador. No obstante,
la cola izquierda es de una longitud ligeramente mayor, lo cual es
indicativo de la asimetría mencionada, al estar los datos más
concentrados alrededor de valores más altos.

El QQPlot o diagrama cuantil-cuantil nos presenta una comparativa entre
los cuantil muestrales de los residuos estandarizados y los cuantiles
teóricos de una normal estándar. Si los residuos estandarizados
presentaran una distribución normal de media 0 y varianza 1, se
situarían alrededor de la recta diagonal resaltada. En nuestro caso,
vemos que en la zona central el ajuste es bueno, pero hay una cierta
desviación en las colas. Esto es especialmente notorio en la superior,
donde los cuantiles muestrales son algo inferiores a los cuantiles
teóricos de una normal, que es lógico y coherente con la asimetría
indicada anteriormente.

Ahora bien, una representación visual es solamente un apoyo al estudio,
y no podemos inferir de ella una conclusión estadísticamente
definitoria. De hecho, pequeñas desviaciones con respecto a la hipótesis
de linealidad, por ejemplo, podrían tener efecto sobre los gráficos
obtenidos. Por ello , emplearemos directamente un test sobre los errores
estandarizados con respecto a una distribución normal. Aunque hay varias
opciones adecuadas, como el test de Kolmogorov-Smirnov y el test de
Lilliefoids, el más ampliamente usado con este propósito es el test de
Shapiro-Wilk, especialmente diseñado para contrastes de normalidad:

\[
\begin{cases}
H_0: \epsilon\text{ sigue una distribución normal}\\
H_a: \epsilon\text{ no sigue una distribución normal}
\end{cases}
\]

Ejecutemos pues el contraste de especificación mencionado:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(residuos.estan)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  residuos.estan
## W = 0.98768, p-value = 0.3518
\end{verbatim}

\begin{verbatim}
    Shapiro-Wilk normality test
\end{verbatim}

data: residuos.estan W = 0.98768, p-value = 0.3518

También podemos comprobar los resultados de otros tests:

\begin{Shaded}
\begin{Highlighting}[]
 \CommentTok{\# Semilla para la generación de números aleatorios en ks.test}
\FunctionTok{set.seed}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{Sys.time}\NormalTok{()))                 }
\CommentTok{\# Comprobamos si los residuos estandarizados coinciden en distribución con una muestra aleatoria N(0,1) de n datos}
\CommentTok{\# El contraste es two{-}sided porque estamos interesados en comprobar ambas colas}
\FunctionTok{ks.test}\NormalTok{(residuos.estan, }\FunctionTok{rnorm}\NormalTok{(n), }\AttributeTok{alternative=}\StringTok{"two.sided"}\NormalTok{)     }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  residuos.estan and rnorm(n)
## D = 0.091667, p-value = 0.6945
## alternative hypothesis: two-sided
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Realizamos también un Lillie test}
\FunctionTok{lillie.test}\NormalTok{(residuos.estan)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Lilliefors (Kolmogorov-Smirnov) normality test
## 
## data:  residuos.estan
## D = 0.057751, p-value = 0.4207
\end{verbatim}

\begin{verbatim}
    Two-sample Kolmogorov-Smirnov test
\end{verbatim}

data: residuos.estan and rnorm(n) D = 0.11667, p-value = 0.3877
alternative hypothesis: two-sided Lilliefors (Kolmogorov-Smirnov)
normality test

data: residuos.estan D = 0.057751, p-value = 0.4207

Todos los p-valores obtenidos mediante estos tests son superiores al
\(\alpha\) fijado, 0.01. Por consiguiente, no existen pruebas
estadísticamente significativas a favor de \(H_a\). No tenemos pruebas
en contra de \(H_0\) y, por tanto, podemos asumir que la hipótesis nula
es cierta (que los errores tienen distribución normal).

Una observación adicional: en este caso, tenemos que el tamaño de la
muestra, n, es mayor que 30, de modo que se pueden despreciar las
impurezas debidas a utilizar los residuos en el estudio de la
normalidad, en lugar de los errores (que no están sujetos a la
aplicación del ajuste de mínimos cuadrados).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 120
\end{verbatim}

\hypertarget{independencia}{%
\subsubsection{Independencia}\label{independencia}}

De entre las 4 hipótesis con las que trabaja el modelo, la independencia
de los errores es la más difícil de corroborar. No tenemos información
acerca del proceso de recogida de muestras, por lo que no podemos
garantizarla en base a que los datos hayan sido medidos sobre objetos o
individuos de forma independiente.

Debido a la complejidad inherente a este apartado, nos limitaremos a
comprobar la independencia temporal. Para ello, asumiremos que nuestros
datos han sido medidos a lo largo del tiempo.

Nos preguntamos entonces si existe algún tipo de relación entre las
observaciones, esto es: \[
\begin{cases}
H_0: \epsilon\text{ son incorrelacionados}\\
H_a: \epsilon\text{ son correlacionados de orden k}
\end{cases}
\] En el contraste planteado, \(k\in\mathbb{N}\), \(k>1\), es el
retardo, esto es, la separación entre los instantes de tiempo que
influyen sobre el instante actual. Así, fijado un k y dados unos errores

\end{document}
