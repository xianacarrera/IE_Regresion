---
title: "Trabajo de Evaluación Continua de Modelos de Regresión"
subtitle: Curso 2021/2022
author: "Xiana Carrera Alonso, Pablo Díaz Viñambres"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```

## R Markdown

Poner introducción aquí

o tablas:
\begin{center}
\begin{tabular}{ |c c c| }
 \hline
 celda1 & celda2 & celda3 \\
 \hline
 celda4 & celda5 & celda6 \\  
 celda7 & celda8 & celda9 \\   
  \hline
\end{tabular}
\end{center}

# Introducción
En el siguiente informe se hará un estudio estadístico en el que se analizará la influencia de la variable X sobre la variable Y, en el marco de la regresión lineal. 

## Librerías utilizadas
```{r librerias}
library(ggplot2)      # Para diagrama de dispersión con región de confianza
library(lmtest)
library(sm)
library(rpanel)   
library(viridis)      # Para gradiente de colores en gráfica de normalidad
library(nortest)      # Necesario para lillie.test
library(car)          # Necesario para QQPlot
```

## Lectura de datos
Asimismo, leemos el número de datos n.

En primer lugar, leemos los datos del archivo proporcionado, que cuenta con 76 variables respuesta, Y1, ..., Y76, y una variable explicativa común, X. En nuestro caso, limitaremos el estudio a Y47, que denotaremos sencillamente como Y de aquí en adelante.

Nada más importar el archivo (para lo cual es necesario que el usuario cambie el directorio actual, empleando, por ejemplo, _setwd_ o _Ctrl + May + H_), realizamos un pequeño análisis estadístico de los datos empleando las funciones estándar _head_, _class_, _names_, _str_ y _summary_.

Por comodidad para cálculos posteriores, también guardamos el número de datos, n.

```{r cars}
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # Configurar wd a la carpeta actual (solo en RStudio) 
# Ejemplo de uso de setwd para cambiar el directorio actual:
#setwd("C:\\Users\\Pablo\\Desktop\\IE_Regresion")

# Leemos los datos empleando read.table (por la extensión .txt)
# Indicamos que existe una cabecera, que las columnas están separadas por espacios y que el signo decimal es el punto.
datos <- read.table("datos_trabajo_temas6y7.txt", header=T, sep=" ", dec=".")
# Comprobamos la estructura de las primeras filas
head(datos)

# Comprobamos que el objeto resultante es un data.frame
class(datos)

# Vemos los nombres de las variables
names(datos)

# Comprobamos la estructura de los datos
str(datos)

# Y realizamos un pequeño análisis estadístico
summary(datos)

# Seleccionamos las dos variables de interés
X <- datos[,"X"]
Y <- datos[,"Y47"]

# Guardamos el número de datos
n <- length(Y)
```

# 1) Relación entre variable explicativa y variable respuesta
En primer lugar, calculamos la covarianza entre las variables. Debemos tener en cuenta que R la calcula como una 'cuasi'covarianza, es decir, dividiendo entre $n-1$ en lugar de entre $n$. Para corregirlo, multiplicamos por $n-1$ y dividimos entre $n$, aunque también mostraremos el valor original.

y el coeficiente de correlación de los datos,
con el objetivo de ver si existe relación lineal entre las variables.

```{r cov}
covar = cov(X,Y)*(n-1)/n; covar           # Covarianza
cov(X,Y)                                  # Cuasicovarianza
cor(X, Y)                                 # Coeficiente de correlación
```
Como vemos, tanto la covarianza como la correlación son negativas. En el caso de la covarianza, esta no nos indica una medida fiable de la relación entre los datos, ya que depende de la escala de los datos. Sin embargo, la correlación, con un valor de -0.95 nos da a entender una relación de proporcionalidad inversa entre X e Y, que podremos corroborar posteriormente al ver el diagrama de dispersión. 

A  continuación hallamos el vector de medias o centro de gravedad aplicando \texttt{mean} en ambas variables:

```{r medias}
mX <- mean(X)
mY <- mean(Y)
```

Y con la siguiente función generamos el diagrama de dispersión de los datos:

```{r dispersion, echo = FALSE}
representar <- function(){
  plot(X, Y,
       main="Diagrama de dispersión", pch=16,
       sub="Subtítulo")
  
  # Añadimos un punto para el vector de medias
  points(mX, mY, pch=12, col=3, cex=2)
  
  # Añadimos dos rectas para dividir en cuadrantes
  abline(v=mX, col=3, lty=1, lwd=2)   # Vertical
  abline(h=mY, col=3, lty=1, lwd=2)   # Horizontal
  
  
  grid(nx = NULL, ny = NULL, lty = 2, col = "lightgray", lwd = 1)
}

representar()
```
Fácilmente observamos que la nube de puntos toma una forma descendente, lo cuál encaja con el hecho de que la correlación entre X e Y sea negativa. También vemos que los datos están, de forma aproximada, uniformemente alineados en torno a una forma rectilínea. Todo esto motiva el establecimiento de un modelo lineal para la relación entre ambas variables. Recordemos que los modelos lineales son de la forma:
$$
Y = \beta_0 + \beta_1X + \epsilon
$$
Ajustamos entonces este modelo a nuestros datos mediante la función lm:
```{r modelo}
modelo = lm(Y~X); modelo
```
y obtenemos un intercepto $\beta_0 = 4.184$ y una pendiente de $\beta_1 = -1.023$, lo cuál concuerda con lo observado anteriormente en la nube de puntos. 

En los siguientes ejercicios, analizaremos más en profundidad este modelo. Además, lo validaremos frente a otros modelos como los polinómicos o los no paramétricos.

## Ejercicio 2
### Estimación puntual a mano
Para la estimación puntual de los parámetros intercepto $\beta_0$, pendiente
$beta_1$ y varianza del error $\sigma^2$ podemos aplicar directamente las fórmulas
obtenidas en la parte teórica de la asignatura:
```{r estpuntmano}
var.X <- var(X)*(n-1)/n
beta0.gorro = mY - covar*mX/var.X; beta0.gorro
beta1.gorro = covar/var.X; beta1.gorro
var.error = sum((Y - beta0.gorro - beta1.gorro*X)^2)/(n-2); var.error
sd.error = sqrt(var.error); sd.error
```

### Estimación puntual automática
De manera alternativa, podemos obtenrlas a partir del propio modelo creado anteriomente por $\mathbb{R}$:
```{r estpuntauto}
modelo    # Información del modelo
modelo$coefficients         # beta0 gorro y beta1 gorro

# En modelo$residuals están los residuos
sum(modelo$residuals^2)/(n-2)
```


```{r dispersionReg, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Incluimos también una gráfica adicional usando la librería _ggplot2_ e incluyendo la región
o intervalo de confianza para los datos al nivel del 99%:
```{r dispersionRegGGPLOT, echo=FALSE}
p3 <- ggplot(datos, aes(x=X, y=Y)) +
  geom_point() +
  geom_smooth(formula=y~x, level=0.99, method=lm, color="red", fill="#666666", se=TRUE) + 
  labs(y = "Variable respuesta",
       x = "Variable explicativa",
       title = "Modelo lineal simple, con región de confianza al 95%")
p3
```

## Ejercicio 3
\textit{Calcula los intervalos de confianza para los parámetros del modelo de nivel 99%.
Interpreta los resultados obtenidos.}
En primer lugar, establecemos el nivel de significación $\alpha$.
```{r alfa}
alfa <- 1 - 0.99
```

A continuación, hallamos los intervalos para
<!--El pivote es ((PASAR A LATEX)) beta0.gorro - beta0/(sqrt(var.gorro*(1/n+mX^2/(n*var.X))) que es una
T de Student con n-2 grados de libertad-->

```{r icbeta0mano}
beta0.cuantil <- qt(1-alfa/2, df=n-2); beta0.cuantil
beta0.extremoinferior <- beta0.gorro - beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.extremosuperior <- beta0.gorro + beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.IC <- c(beta0.extremoinferior, beta0.extremosuperior); beta0.IC
```
<!--
El pivote es ((PASAR A LATEX)) pivote beta1.gorro - beta1/sqrt(var.gorro/ (var.X * n)) que es una
T de Student con n-2 grados de libertad
-->

```{r icbeta1mano}
beta1.cuantil <- beta0.cuantil
beta1.extremoinferior <- beta1.gorro - beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.extremosuperior <- beta1.gorro + beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.IC <- c(beta1.extremoinferior, beta1.extremosuperior); beta1.IC
```
<!--
El pivote para la varianza del error será ((PASAR A LATEX))
pivote -> (n-2)*var.error^2/varianzaerror^2 que es una chi-cuadrado con n-2
grados de libertad-->
```{r icvarsmano}
var.error.cuantilinferior <- qchisq(alfa/2, df=n-2)
var.error.cuantilsuperior <- qchisq(1-alfa/2, df=n-2)
var.error.extremoinferior <- (n-2)*var.error^2/var.error.cuantilsuperior
var.error.extremosuperior <- (n-2)*var.error^2/var.error.cuantilinferior
var.error.IC <- c(var.error.extremoinferior, var.error.extremosuperior); var.error.IC
```

Pero también podemos utilizar las funciones de R para hacerlo de forma automática:
- IC para beta0 y beta1 asumiendo que la varianza es desconocida
```{r icbeta0beta1}
confint(modelo, level=0.99)
```

No hay una automatización del cálculo de la varianza del error

## Ejercicio 4
\textit{Realiza los contrates de significación asociados al intercepto y a la pendiente del
modelo de regresión considerado. Interpreta los resultados obtenidos. En base a
los resultados obtenidos, ¿tendría sentido considerar otro modelo más sencillo?}
A continuación, realizaremos los contrastes de significación sobre el modelo con el objetivo de determinar si el modelo se podría simplificar a uno con menos variables o no.
En primer lugar, realizaremos el contraste de forma manual a partir de los estadísticos de contraste basado en el pivote de la estimaciones puntuales previas:
```{r signifmano}
# Contraste de significacion para beta0
beta0.t <- abs(beta0.gorro) / (sqrt(var.error * (1/n + mX^2/(n*var.X)))); beta0.t
beta1.t <- abs(beta1.gorro) / (sd.error / sqrt(n*var.X)); beta1.t
# Rechazamos la hipótesis nula de que el modelo tiene origen de 0
beta0.t > beta0.cuantil 
# Rechazamos la hipótesis nula de que el modelo no tiene pendiente
beta1.t > beta1.cuantil
# El p-valor es 0 --> La hipótesis nula es falsa para cualquier nivel de signif. --> El modelo tiene un intercepto distinto de 0
beta0.pvalor = dt(beta0.t, df=n-2); beta0.pvalor
# El p-valor es 0 --> La hipótesis nula es falsa para cualquier nivel de signif. --> El modelo tiene una pendiente distinta de 0
beta1.pvalor = dt(beta1.t, df=n-2); beta1.pvalor
```

De esto deducimos que existen pruebas estadísticamente significativas de que $\beta_0 \neq 0$, lo cuál nos indica que el intercepto es distinto de 0. Por otro lado, también existen pruebas de $\beta_1 \neq 0$, de dónde deducimos que realmente la variable explicativa influye en la variable respuesta. 

Alternativamente, podemos obtener los valores de estos dos contrastes de significación y su p-valor a partir de los datos presentes en el modelo de R. Para esto, usaremos la función summary:
```{r signifauto}
summary(modelo)
```
En concreto, los valores relevantes son el t-value y el Pr(>|t|) de las filas (Intercept) y X que se corresponden al valor observado del estadístico observado y su p-valor en el contraste sobre el intercepto $\beta_0$ y la pendiente $\beta_1$. Obtenemos los mismos datos que en el cálculo manual.

En base a los resultados obtenidos anteriormente, decidimos no simplificar más nuestro modelo y continuar realizando regresión lineal.

## Ejercicio 5
\textit{Si consideramos que la variable 𝑋𝑋 toma 3 nuevos valores: 2, 4 y 6 unidades, proporciona intervalos de predicción e intervalos de confianza para la media condicionada de la variable 𝑌𝑌. Interpreta los resultados obtenidos.}

En este apartado, consideramos 3 nuevos valores para la variable explicativa $X = 2, 4, 6$. Para obtener intervalos de confianza para la media de Y condicionada a estos valores y de predicción, es necesario comprobar primero que estos datos están dentro del rango de observación de X. Esto es debido a que no sabemos como se comporta el modelo fuera del rango observado, y nuestro objetivo es predecir y no extrapolar.
```{r validacionnuevosdatos}
nuevosValores <- c(2, 4, 6)
# El rango está contenido
min(X) < min(nuevosValores) && max(X) > max(nuevosValores)
# Construimos un data.frame  con los nuevos datos ya que predict necesita este formato para sus predicciones
nuevosDatos = data.frame("X" = nuevosValores)
```
Habiendo realizado esta comprobación, ya podemos obtener los intervalos utilizando la función predict sobre el modelo de R. Obtendremos ambos intervalos para los niveles de significación 0.95 y 0.99. ((TODO: REVISAR, ESTOS ESTÁN BIEN PERO DEBERÍAN SER CONSISTENTES CON OTRAS PARTES DONDE COJAMOS ALFAS ARBITRARIOS))

En primer lugar, pasando el argumento $\texttt{interval = "confidence"}$ obtenemos los asociados a la media condicionada.
```{r intmediacond}
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.99)
```
Y para obtener los intervalos de predicción, los cuáles serán más amplios que los anteriores, pasamos el argumento $\texttt{interval = "prediction"}$
```{r intprediccion}
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.99)
```
