---
title: "Trabajo de Evaluación Continua de Modelos de Regresión"
subtitle: Curso 2021/2022
author: "Xiana Carrera Alonso, Pablo Díaz Viñambres"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Poner introducción aquí


Además, en este tipo de documentos también puedes emplear sintaxis de LaTeX como ecuaciones:

$$
\begin{cases}
H_0: \beta_1=0,\\
H_a: \beta_1\neq 0
\end{cases}
$$
o tablas:
\begin{center}
\begin{tabular}{ |c c c| }
 \hline
 celda1 & celda2 & celda3 \\
 \hline
 celda4 & celda5 & celda6 \\  
 celda7 & celda8 & celda9 \\   
  \hline
\end{tabular}
\end{center}


## Incluir gráficos

Por otra parte, también puedes incluir representaciones gráficas en tu documento empleando la sintaxis:

```{r pressure, echo=FALSE}
boxplot(cars$dist)
```

Fíjate que añadiendo el parámetro `echo = FALSE' en las opciones del \emph{chuck} evitamos que se imprima el código de R que empleamos para generar la representación gráfica.


# Introducción
En este documento se describe y documenta el ajuste y análisis de un modelo de regresión lineal simple en base a los datos proporcionados para una variable explicativa X y una variable respuesta Y. 

El estudio se fundamentará en los conceptos teóricos relacionados con los modelos de regresión lineal simple y su validación que fueron estudiados a lo largo de los Temas 6 y 7 de la asignatura de Inferencia Estadística. Se hará referencia explícita a los mismos a medida que sean empleados.

Asimismo, se utilizará R para realizar las operaciones necesarias para el análisis. Los detalles relativos al empleo de sus funciones se detallarán o bien en el propio informe o bien a través de comentarios sobre el código.

# Cuestiones preliminares
En cada una de las secciones del documento se trabajará con $\alpha = 0.01$ para los distintos contrastes, intervalos de confianza, etc. planteados. Equivalentemente, se empleará un nivel de significación $1 - \alpha = 0.99$.

Esta elección responde a la imposición (PENSAR PALABRA MEJOR) de emplear un nivel de significación del 99% para la construcción de intervalos de confianza de los parámetros del modelo. Es preferible mantener un nivel uniforme durante todo el estudio, con el objetivo de mantener un criterio homogéneo a la hora de interpretar los resultados y hacer inferencia en consecuencia. 


# Librerías
Cargamos a continuación todas las librerías que utilizaremos a lo largo de la ejecución. Si alguno de los paquetes no ha sido previamente instalado, debe ejecutarse la instrucción _install.packages("nombre_del_paquete")_, 
```{r cars}
#install.packages("paquete_de_ejemplo")

```


# Lectura de datos

En primer lugar, leemos los datos del archivo proporcionado, que cuenta con 76 variables respuesta, Y1, ..., Y76, y una variable explicativa común, X. En nuestro caso, limitaremos el estudio a Y47, que denotaremos sencillamente como Y de aquí en adelante.

Nada más importar el archivo (para lo cual es necesario que el usuario cambie el directorio actual, empleando, por ejemplo, _setwd_ o _Ctrl + May + H_), realizamos un pequeño análisis estadístico de los datos empleando las funciones estándar _head_, _class_, _names_, _str_ y _summary_.

Por comodidad para cálculos posteriores, también guardamos el número de datos, n.

```{r cars}
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # Configurar wd a la carpeta actual (solo en RStudio) 
# Ejemplo de uso de setwd para cambiar el directorio actual:
#setwd("C:\\Users\\Pablo\\Desktop\\IE_Regresion")

# Leemos los datos empleando read.table (por la extensión .txt)
# Indicamos que existe una cabecera, que las columnas están separadas por espacios y que el signo decimal es el punto.
datos <- read.table("datos_trabajo_temas6y7.txt", header=T, sep=" ", dec=".")
# Comprobamos la estructura de las primeras filas
head(datos)

# Comprobamos que el objeto resultante es un data.frame
class(datos)

# Vemos los nombres de las variables
names(datos)

# Comprobamos la estructura de los datos
str(datos)

# Y realizamos un pequeño análisis estadístico
summary(datos)

# Seleccionamos las dos variables de interés
X <- datos[,"X"]
Y <- datos[,"Y47"]

# Guardamos el número de datos
n <- length(Y)
```

# 1) Relación entre variable explicativa y variable respuesta
En primer lugar, calculamos la covarianza entre las variables. Debemos tener en cuenta que R la calcula como una 'cuasi'covarianza, es decir, dividiendo entre $n-1$ en lugar de entre $n$. Para corregirlo, multiplicamos por $n-1$ y dividimos entre $n$, aunque también mostraremos el valor original.

y el coeficiente de correlación de los datos,
con el objetivo de ver si existe relación lineal entre las variables.

```{r cars}
covar = cov(X,Y)*(n-1)/n; covar           # Covarianza
cov(X,Y)                                  # Cuasicovarianza
cor(X, Y)                                 # Coeficiente de correlación
```

A  continuación hallamos el vector de medias o centro de gravedad 
para añadirlo posteriormente a la gráfica:

```{r cars}
mX <- mean(X)
mY <- mean(Y)
```

Y con la siguiente función generamos la gráfica de dispersión básica:

```{r pressure, echo = FALSE}
representar <- function(){
  plot(X, Y,
       main="Diagrama de dispersión", pch=16,
       sub="Subtítulo")
  
  # Añadimos un punto para el vector de medias
  points(mX, mY, pch=12, col=3, cex=2)
  
  # Añadimos dos rectas para dividir en cuadrantes
  abline(v=mX, col=3, lty=1, lwd=2)   # Vertical
  abline(h=mY, col=3, lty=1, lwd=2)   # Horizontal
  
  
  grid(nx = NULL, ny = NULL, lty = 2, col = "lightgray", lwd = 1)
}

representar()
```

Finalmente, establecemos el modelo lineal entre los datos 
```{r cars}
modelo=lm(Y~X)
modelo
```

## Ejercicio 2
### Estimación puntual a mano
Para la estimación puntual de los parámetros intercepto $\beta_0$, pendiente
$beta_1$ y varianza del error $\sigma^2$ podemos aplicar directamente las fórmulas
obtenidas en la parte teórica de la asignatura:
```{r cars}
var.X <- var(X)*(n-1)/n
beta0.gorro = mY - covar*mX/var.X; beta0.gorro
beta1.gorro = covar/var.X; beta1.gorro
var.error = sum((Y - beta0.gorro - beta1.gorro*X)^2)/(n-2); var.error
sd.error = sqrt(var.error); sd.error
```

### Estimación puntual automática
De manera alternativa, podemos obtenrlas a partir del propio modelo creado anteriomente por $\mathbb{R}$:
```{r cars}
modelo    # Información del modelo
modelo$coefficients         # beta0 gorro y beta1 gorro

# En modelo$residuals están los residuos
sum(modelo$residuals^2)/(n-2)
```


```{r pressure, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Incluimos también una gráfica adicional usando la librería _ggplot2_ e incluyendo la región
o intervalo de confianza para los datos al nivel del 99%:
```{r pressure, echo=FALSE}
library(ggplot2)
p3 <- ggplot(datos, aes(x=X, y=Y)) +
  geom_point() +
  geom_smooth(formula=y~x, level=0.99, method=lm, color="red", fill="#666666", se=TRUE) + 
  labs(y = "Variable respuesta",
       x = "Variable explicativa",
       title = "Modelo lineal simple, con región de confianza al 95%")
p3
```

## Ejercicio 3
### A mano
En el siguiente apartado, En primer lugar, establecemos el nivel de significación $\alfa$.
```{r cars}
alfa <- 1 - 0.99
```

A continuación, hallamos los intervalos para 
El pivote es ((PASAR A LATEX)) beta0.gorro - beta0/(sqrt(var.gorro*(1/n+mX^2/(n*var.X))) que es una
T de Student con n-2 grados de libertad

```{r cars}
beta0.cuantil <- qt(1-alfa/2, df=n-2); beta0.cuantil
beta0.extremoinferior <- beta0.gorro - beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.extremosuperior <- beta0.gorro + beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.IC <- c(beta0.extremoinferior, beta0.extremosuperior); beta0.IC
```

El pivote es ((PASAR A LATEX)) pivote beta1.gorro - beta1/sqrt(var.gorro/ (var.X * n)) que es una
T de Student con n-2 grados de libertad

```{r cars}
beta1.cuantil <- beta0.cuantil
beta1.extremoinferior <- beta1.gorro - beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.extremosuperior <- beta1.gorro + beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.IC <- c(beta1.extremoinferior, beta1.extremosuperior); beta1.IC
```

El pivote para la varianza del error será ((PASAR A LATEX))
pivote -> (n-2)*var.error^2/varianzaerror^2 que es una chi-cuadrado con n-2
grados de libertad
```{r cars}
var.error.cuantilinferior <- qchisq(alfa/2, df=n-2)
var.error.cuantilsuperior <- qchisq(1-alfa/2, df=n-2)
var.error.extremoinferior <- (n-2)*var.error^2/var.error.cuantilsuperior
var.error.extremosuperior <- (n-2)*var.error^2/var.error.cuantilinferior
var.error.IC <- c(var.error.extremoinferior, var.error.extremosuperior); var.error.IC
```

Pero también podemos utilizar las funciones de R para hacerlo de forma automática:
- IC para beta0 y beta1 asumiendo que la varianza es desconocida
```{r cars}
confint(modelo, level=0.99)
```

No hay una automatización del cálculo de la varianza del error

# Ejercicio 4
A continuación, realizaremos los contrastes de significación sobre el modelo con el objetivo de determinar si el modelo se podría simplificar a uno con menos variables o no.
En primer lugar, realizaremos el contraste de forma manual a partir de los estadísticos de contraste basado en el pivote de la estimaciones puntuales previas:
```{r cars}
# Contraste de significacion para beta0
beta0.t <- abs(beta0.gorro) / (sqrt(var.error * (1/n + mX^2/(n*var.X)))); beta0.t
beta1.t <- abs(beta1.gorro) / (sd.error / sqrt(n*var.X)); beta1.t
# Rechazamos la hipótesis nula de que el modelo tiene origen de 0
beta0.t > beta0.cuantil 
# Rechazamos la hipótesis nula de que el modelo no tiene pendiente
beta1.t > beta1.cuantil
# El p-valor es 0 --> La hipótesis nula es falsa para cualquier nivel de signif. --> El modelo tiene un intercepto distinto de 0
beta0.pvalor = dt(beta0.t, df=n-2); beta0.pvalor
# El p-valor es 0 --> La hipótesis nula es falsa para cualquier nivel de signif. --> El modelo tiene una pendiente distinta de 0
beta1.pvalor = dt(beta1.t, df=n-2); beta1.pvalor
```

De esto deducimos que existen pruebas estadísticamente significativas de que $\beta_0 \neq 0$, lo cuál nos indica que el intercepto es distinto de 0. Por otro lado, también existen pruebas de $\beta_1 \neq 0$, de dónde deducimos que realmente la variable explicativa influye en la variable respuesta. 

Alternativamente, podemos obtener los valores de estos dos contrastes de significación y su p-valor a partir de los datos presentes en el modelo de R. Para esto, usaremos la función summary:
```{r cars}
summary(modelo)
```
En concreto, los valores relevantes son el t-value y el Pr(>|t|) de las filas (Intercept) y X que se corresponden al valor observado del estadístico observado y su p-valor en el contraste sobre el intercepto $\beta_0$ y la pendiente $\beta_1$. Obtenemos los mismos datos que en el cálculo manual.

En base a los resultados obtenidos anteriormente, decidimos no simplificar más nuestro modelo y continuar realizando regresión lineal.

## Ejercicio 5
En este apartado, consideramos 3 nuevos valores para la variable explicativa $X = 2, 4, 6$. Para obtener intervalos de confianza para la media de Y condicionada a estos valores y de predicción, es necesario comprobar primero que estos datos están dentro del rango de observación de X. Esto es debido a que no sabemos como se comporta el modelo fuera del rango observado, y nuestro objetivo es predecir y no extrapolar.
```{r cars}
nuevosValores <- c(2, 4, 6)
# El rango está contenido
min(X) < min(nuevosValores) && max(X) > max(nuevosValores)
# Construimos un data.frame  con los nuevos datos ya que predict necesita este formato para sus predicciones
nuevosDatos = data.frame("X" = nuevosValores)
```
Habiendo realizado esta comprobación, ya podemos obtener los intervalos utilizando la función predict sobre el modelo de R. Obtendremos ambos intervalos para los niveles de significación 0.95 y 0.99. ((TODO: REVISAR, ESTOS ESTÁN BIEN PERO DEBERÍAN SER CONSISTENTES CON OTRAS PARTES DONDE COJAMOS ALFAS ARBITRARIOS))

En primer lugar, pasando el argumento $\texttt{interval = "confidence"}$ obtenemos los asociados a la media condicionada.
```{r cars}
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.99)
```
Y para obtener los intervalos de predicción, los cuáles serán más amplios que los anteriores, pasamos el argumento $\texttt{interval = "prediction"}$
```{r cars}
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.99)
```
# Ejercicio 6 
<!-- 
  lol este RMarkdown usa html comments
  Calcula alguna medida de bondad de ajuste del modelo lineal simple considerado. 
  de los apuntes:
    Para analizar el cumplimiento de la hipótesis de normalidad, no emplearemos los gráficos an-
    teriores sino que efectuaremos un test de bondad de ajuste a la distribución normal sobre los
    residuos. Para ello, podemos emplear un test de tipo Kolmogorov-Smirnov, el test de Shapiro-
    Wilk o un test ji-cuadrado. Nos decantaremos por el test de Shapiro-Wilk, que está especial-
    mente diseñado para el contraste de normalidad. Omitimos los detalles sobre la construcción
    de este test.
  así que habrá que usar el test de ben saphiro
-->


# Ejercicio 7
  Las técnicas de inferencia empleadas hasta el momento son ciertas bajo el supuesto de que las 4 hipótesis del modelo de regresión lineal simple (linealidad, homocedasticidad, normalidad e independencia) se verifican. De lo contrario,
  no todas las interpretaciones obtenidas seguirían siendo válidas. Por ejemplo, si no se cumplieran las hipótesis de homocedasticidad, normalidad e independencia, los intervalos de confianza que hemos obtenido no serían válidos.

## Linealidad
En primer lugar, podemos tratar de aventurar si se los datos siguen una tendencia lineal. Emplearemos una aproximación exploratoria, a través de una interpretación gráfica. Para ello, revisitemos la representación previamente definida.

```{r pressure, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Vemos que los puntos parecen distribuirse en torno a la recta de forma lineal. Si bien hay datos un tanto atípicos, especialmente en los extremos, esto no es lo suficientemente significativo como para rechazar la hipótesis. Tampoco se ve un patrón evidente en los datos (es esto lo que debemos tratar de detectar, y no solo corroborar que haya el mismo número de puntos por encima/debajo de la recta, que no es suficiente como para indicar linealidad).

Nótese que aunque se puede apreciar una menor concentración de puntos para valores de X comprendidos alrededor del valor 4, esto no es indicativo de una falta de linealidad. Dado que trabajamos bajo diseño fijo, se tiene que achacar a decisiones sobre las condiciones de medición o al propio diseño del experimento. Esta observación se puede comprobar a través del siguiente cuadro:

```{r cars}
# Representamos el número de valores de X en cada intervalo de longitud 0.5, comenzando desde el mayor entero menor
# o igual que el dato mínimo, y finalizando en el menor entero mayor o igual que el dato máximo.
table(cut(X, breaks=seq(from=floor(min(X)), to=ceiling(max(X)), by=0.5)))
```

Con el objetivo de realizar una prueba más precisa, planteamos el siguiente contraste de hipótesis. Como hipótesis nula tenemos que la variable respuesta siga el modelo lineal simple que hemos estado considerando, y como hipótesis nula, que siga un modelo parabólico, donde hay dependencia de la variable explicativa al cuadrado:
$$
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=\beta_0+\beta_1X+\beta_2*X^2\epsilon
\end{cases}
$$

Ejecutamos la prueba:

```{r cars}
library(lmtest)
# Empleamos power = 2 porque estamos considerando una alternativa cuadrática
resettest(modelo, power = 2)
```

Vemos que el p-valor es de 0.7613. INTERPRETAR.

No obstante, este contraste solo nos ha aportado información sobre la equiparación con un modelo cuadrático. Si buscáramos una confirmación perfecta, teórica, deberíamos seguir contrastando con todos los valores de power. Dado que esto es impracticable experimentalmente, podemos plantearnos en su lugar un contraste más general, con una alternativa no parámetrica:
$$
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=m(X)+\epsilon
\end{cases}
$$

Haciendo uso del paquete _sm_, realizamos la prueba de hipótesis:
```{r cars}
library(sm)
library(rpanel)            
# Importamos rpanel para abrir un panel interactivo para la representación
# Los valores que sabemos interpretar son los que aparecen con las opciones por defecto
# Indicamos test=T para que se nos muestre un p-valor.
sm.regression(X, Y, model="linear", panel=T, test=T)
```

La interpretación de la figura resultante es la siguiente. Con una línea negra nos aparece marcada una estimación no paramétrica de la regresión (sin asumir linealidad), y en azul, una región de confianza para el modelo lineal simple. Vemos que la línea negra se encuentra siempre dentro de la región azul. Por tanto, podemos asumir que la hipótesis nula es cierta, esto es, que los datos verifican la hipótesis de linealidad.
FALTA ANALIZAR EL P-VALOR


## Homocedasticidad
Contrapongamos ahora los residuos del modelo a la variable explicativa. Se muestra también el diagrama de dispersión original:
```{r pressure, echo=FALSE}
par(mfrow=c(1,2))

representar()
abline(modelo, col="red", lwd=2)

residuos <- modelo$residuals

plot(X, residuos,
   main="Diagrama de dispersión", pch=16,
   sub="Subtítulo")
abline(h=0, col="gray", lwd=2)

par(mfrow=c(1,1))

```

Queremos comprobar ahora si la varianza del error, $\sigma^2$, es la misma independientemente del valor que tome la variable explicativa. Vemos que la distribución de los residuos en el diagrama no sigue un patrón evidente, y que su desviación con respecto a la recta $x=0$ parece ser la misma sin importar el intervalo de X considerado. 

Tampoco sobre el diagrama de dispersión de la variable respuesta observamos una tendencia significativa acera de las desviaciones con la recta de regresión. En conjunción con lo anterior, podríamos aventurar, a primera vista, que los datos muestrales son verdaderamente homocedásticos.

Sí destacamos que la interpretación para la región central, en aproximadamente $(4, 4.5)$, puede no ser muy precisa, por falta de datos. Sin embargo, esto no basta para desmentir la hipótesis de homocedasticidad.

Para tener una confirmación precisa, nos planteamos el siguiente contraste de hipótesis:
$$
\begin{cases}
H_0: \text{modelo homocedástico}\\
H_a: \text{modelo heterocedástico}
\end{cases}
$$

Ejecutamos un test de Harrison-McCabe con R, haciendo uso del previamente cargado paquete _lmtest_:
```{r cars}
hmctest(Y~X)
```
El p-valor es de 0.763.


## Normalidad
Para corroborar que el error tiene distribución normal, haremos varias representaciones gráficas que nos permitan intuir si la hipótesis se ajusta a los datos. Trabajaremos con los residuos estandarizados, pues no tienen la misma varianza y la correlación entre cada 2 de ellos puede ser distinta (provienen de distribuciones diferentes).

Presentamos 3 gráficos: un histograma, un boxplot y un qqplot (para el cual necesitamos la librería _car_), aunque centraremos nuestra atención en el último de ellos, el más relevante en lo que concierne al estudio de la normalidad.

```{r pressure, echo=FALSE}
residuos.estan = rstandard(modelo)

par(mfrow = c(1, 3 )) 

library(viridis)
hist(residuos.estan, col=c(viridis(n=5, begin=0, end=0.8), viridis(n=1, begin=1), viridis(n=5, begin=0.8, end=0)))
rug(residuos.estan)

boxplot(residuos.estan, col="gray")

library(car)
qqPlot(residuos.estan)
```

En el histograma podemos apreciar una cierta asimetría hacia la derecha (valores más altos). En el boxplot o diagrama de caja vemos que la media está centrada en el centro de la caja, un buen indicador. No obstante, la cola izquierda es de una longitud ligeramente mayor, lo cual es indicativo de la asimetría mencionada, al estar los datos más concentrados alrededor de valores más altos.

El QQPlot o diagrama cuantil-cuantil nos presenta una comparativa entre los cuantil muestrales de los residuos estandarizados y los cuantiles teóricos de una normal estándar. Si los residuos estandarizados presentaran una distribución normal de media 0 y varianza 1, se situarían alrededor de la recta diagonal resaltada. En nuestro caso, vemos que en la zona central el ajuste es bueno, pero hay una cierta desviación en las colas. Esto es especialmente notorio en la superior, donde los cuantiles muestrales son algo inferiores a los cuantiles teóricos de una normal, que es lógico y coherente con la asimetría indicada anteriormente.

Ahora bien, una representación visual es solamente un apoyo al estudio, y no podemos inferir de ella una conclusión estadísticamente definitoria. Para ello , emplearemos  directamente un test de bondad de ajuste sobre los errores estandarizados con respecto a una distribución normal. Aunque hay varias opciones adecuadas, como el test de Kolmogorov-Smirnov y el test de Lilliefoids, el más ampliamente usado con este propósito es el test de Shapiro-Wilk, especialmente diseñado para contrastes de normalidad:

$$
\begin{cases}
H_0: \epsilon\text{ sigue una distribución normal}\\
H_a: \epsilon\text{ no sigue una distribución normal}
\end{cases}
$$

Ejecutemos pues el contraste de especificación mencionado:
```{r cars}
shapiro.test(residuos.estan)
```

También podemos comprobar los resultados de otros tests:
```{r cars}
ks.test(residuos.estan)
library(nortest)     # Necesario para lillie.test
lillie.test(residuos.estan)
```

Una observación adicional: en este caso, tenemos que el tamaño de la muestra, n, es mayor que 30, de modo que se pueden despreciar las impurezas debidas a utilizar los residuos en el estudio de la normalidad, en lugar de los errores (que no están sujetos a la aplicación del ajuste de mínimos cuadrados).
```{r cars}
n
````


## Independencia
De entre las 4 hipótesis con las que trabaja el modelo, la independencia de los errores es la más difícil de corroborar. No tenemos información acerca del proceso de recogida de muestras, por lo que no podemos garantizarla en base a que los datos hayan sido medidos sobre objetos o individuos de forma independiente.

Debido a la complejidad inherente a este apartado, nos limitaremos a comprobar la independencia temporal. Para ello, asumiremos que nuestros datos han sido medidos a lo largo del tiempo. 

Nos preguntamos entonces si existe algún tipo de relación entre las observaciones, esto es:
$$
\begin{cases}
H_0: \epsilon\text{ son incorrelacionados}\\
H_a: \epsilon\text{ son correlacionados de orden k}
\end{cases}
$$
En el contraste planteado, $k\in\mathbb{N}$, $k>1$, es el retardo, esto es, la separación entre los instantes de tiempo que influyen sobre el instante actual. Así, fijado un k y dados unos errores 


BONDAD DE AJUSTE ES EL COEFICIENTE DE DETERMINACIÓN (ES UNA MEDIDA DE CUÁNTO DE BUENO ES EL MODELO). EL R^2 AJUSTADO ES OTRA MEDIDA DE BONDAD DE AJUSTE. TAMBIÉN HAY CONTRASTES. ESTÁ EN EL SUMMARY.

ACEPTAR LA H0 EN CONTRASTE LINEALIDAD POLINÓMICO SOLO SIGNIFICA QUE MI MODELO ES MEJOR QUE UN POLINÓMICO DE ORDEN 2, 3...

EL SM TE LO CONTRASTA CON ALTERNATIVA NO PARAMÉTRICA -> ES MEJOR MI MODELO QUE CUALQUIER OTRA COSA? CON HACER ESTE ES SUFICIENTE

a veces las formas raras en homocedasticidad (qqplot) se pueden deber a falta de linealidad. Es más conncluyente el contraste


HAY QUE FIJAR EL ALFA DESDE EL PRINCIPIO. METER YA DESDE LA INTRODUCCIÓN. EN ESTE CASO TENDREMOS QUE FIJAR ALFA = 1% (NIVEL 99%) POR EL APARTADO 3

