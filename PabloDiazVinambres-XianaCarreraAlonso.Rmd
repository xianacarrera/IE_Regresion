---
title: "Trabajo de Evaluaci贸n Continua de Modelos de Regresi贸n"
subtitle: Curso 2021/2022
author: "Xiana Carrera Alonso, Pablo D铆az Vi帽ambres"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```

## R Markdown

Poner introducci贸n aqu铆

o tablas:
\begin{center}
\begin{tabular}{ |c c c| }
 \hline
 celda1 & celda2 & celda3 \\
 \hline
 celda4 & celda5 & celda6 \\  
 celda7 & celda8 & celda9 \\   
  \hline
\end{tabular}
\end{center}

# Introducci贸n
En el siguiente informe se har谩 un estudio estad铆stico en el que se analizar谩 la influencia de la variable X sobre la variable Y, en el marco de la regresi贸n lineal. 

## Librer铆as utilizadas
```{r librerias}
library(ggplot2)      # Para diagrama de dispersi贸n con regi贸n de confianza
library(lmtest)
library(sm)
library(rpanel)   
library(viridis)      # Para gradiente de colores en gr谩fica de normalidad
library(nortest)      # Necesario para lillie.test
library(car)          # Necesario para QQPlot
```

## Lectura de datos
Asimismo, leemos el n煤mero de datos n.

En primer lugar, leemos los datos del archivo proporcionado, que cuenta con 76 variables respuesta, Y1, ..., Y76, y una variable explicativa com煤n, X. En nuestro caso, limitaremos el estudio a Y47, que denotaremos sencillamente como Y de aqu铆 en adelante.

Nada m谩s importar el archivo (para lo cual es necesario que el usuario cambie el directorio actual, empleando, por ejemplo, _setwd_ o _Ctrl + May + H_), realizamos un peque帽o an谩lisis estad铆stico de los datos empleando las funciones est谩ndar _head_, _class_, _names_, _str_ y _summary_.

Por comodidad para c谩lculos posteriores, tambi茅n guardamos el n煤mero de datos, n.

```{r cars}
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # Configurar wd a la carpeta actual (solo en RStudio) 
# Ejemplo de uso de setwd para cambiar el directorio actual:
#setwd("C:\\Users\\Pablo\\Desktop\\IE_Regresion")

# Leemos los datos empleando read.table (por la extensi贸n .txt)
# Indicamos que existe una cabecera, que las columnas est谩n separadas por espacios y que el signo decimal es el punto.
datos <- read.table("datos_trabajo_temas6y7.txt", header=T, sep=" ", dec=".")
# Comprobamos la estructura de las primeras filas
head(datos)

# Comprobamos que el objeto resultante es un data.frame
class(datos)

# Vemos los nombres de las variables
names(datos)

# Comprobamos la estructura de los datos
str(datos)

# Y realizamos un peque帽o an谩lisis estad铆stico
summary(datos)

# Seleccionamos las dos variables de inter茅s
X <- datos[,"X"]
Y <- datos[,"Y47"]

# Guardamos el n煤mero de datos
n <- length(Y)
```

# 1) Relaci贸n entre variable explicativa y variable respuesta
En primer lugar, calculamos la covarianza entre las variables. Debemos tener en cuenta que R la calcula como una 'cuasi'covarianza, es decir, dividiendo entre $n-1$ en lugar de entre $n$. Para corregirlo, multiplicamos por $n-1$ y dividimos entre $n$, aunque tambi茅n mostraremos el valor original.

y el coeficiente de correlaci贸n de los datos,
con el objetivo de ver si existe relaci贸n lineal entre las variables.

```{r cov}
covar = cov(X,Y)*(n-1)/n; covar           # Covarianza
cov(X,Y)                                  # Cuasicovarianza
cor(X, Y)                                 # Coeficiente de correlaci贸n
```
Como vemos, tanto la covarianza como la correlaci贸n son negativas. En el caso de la covarianza, esta no nos indica una medida fiable de la relaci贸n entre los datos, ya que depende de la escala de los datos. Sin embargo, la correlaci贸n, con un valor de -0.95 nos da a entender una relaci贸n de proporcionalidad inversa entre X e Y, que podremos corroborar posteriormente al ver el diagrama de dispersi贸n. 

A  continuaci贸n hallamos el vector de medias o centro de gravedad aplicando \texttt{mean} en ambas variables:

```{r medias}
mX <- mean(X)
mY <- mean(Y)

c(mX, mY)    # Mostramos el vector de medias
```

Y con la siguiente funci贸n generamos el diagrama de dispersi贸n de los datos:

```{r dispersion, echo = FALSE}
representar <- function(){
  plot(X, Y,
       main="Diagrama de dispersi贸n", pch=16,
       sub="Subt铆tulo")
  
  # A帽adimos un punto para el vector de medias
  points(mX, mY, pch=12, col=3, cex=2)
  
  # A帽adimos dos rectas para dividir en cuadrantes
  abline(v=mX, col=3, lty=1, lwd=2)   # Vertical
  abline(h=mY, col=3, lty=1, lwd=2)   # Horizontal
  
  
  grid(nx = NULL, ny = NULL, lty = 2, col = "lightgray", lwd = 1)
}

representar()
```
F谩cilmente observamos que la nube de puntos toma una forma descendente, lo cu谩l encaja con el hecho de que la correlaci贸n entre X e Y sea negativa. Tambi茅n vemos que los datos est谩n, de forma aproximada, uniformemente alineados en torno a una forma rectil铆nea. Todo esto motiva el establecimiento de un modelo lineal para la relaci贸n entre ambas variables. Recordemos que los modelos lineales son de la forma:
$$
Y = \beta_0 + \beta_1X + \epsilon
$$
Ajustamos entonces este modelo a nuestros datos mediante la funci贸n lm:
```{r modelo}
modelo = lm(Y~X); modelo
```
y obtenemos un intercepto $\beta_0 = 4.184$ y una pendiente de $\beta_1 = -1.023$, lo cu谩l concuerda con lo observado anteriormente en la nube de puntos. 

En los siguientes ejercicios, analizaremos m谩s en profundidad este modelo. Adem谩s, lo validaremos frente a otros modelos como los polin贸micos o los no param茅tricos.

## Ejercicio 2
### Estimaci贸n puntual a mano
Para la estimaci贸n puntual de los par谩metros intercepto $\beta_0$, pendiente
$beta_1$ y varianza del error $\sigma^2$ podemos aplicar directamente las f贸rmulas
obtenidas en la parte te贸rica de la asignatura:
```{r estpuntmano}
var.X <- var(X)*(n-1)/n
beta0.gorro = mY - covar*mX/var.X; beta0.gorro
beta1.gorro = covar/var.X; beta1.gorro
var.error = sum((Y - beta0.gorro - beta1.gorro*X)^2)/(n-2); var.error
sd.error = sqrt(var.error); sd.error
```

### Estimaci贸n puntual autom谩tica
De manera alternativa, podemos obtenrlas a partir del propio modelo creado anteriomente por $\mathbb{R}$:
```{r estpuntauto}
modelo    # Informaci贸n del modelo
modelo$coefficients         # beta0 gorro y beta1 gorro

# En modelo$residuals est谩n los residuos
sum(modelo$residuals^2)/(n-2)
```


```{r dispersionReg, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Incluimos tambi茅n una gr谩fica adicional usando la librer铆a _ggplot2_ e incluyendo la regi贸n
o intervalo de confianza para los datos al nivel del 99%:
```{r dispersionRegGGPLOT, echo=FALSE}
p3 <- ggplot(datos, aes(x=X, y=Y)) +
  geom_point() +
  geom_smooth(formula=y~x, level=0.99, method=lm, color="red", fill="#666666", se=TRUE) + 
  labs(y = "Variable respuesta",
       x = "Variable explicativa",
       title = "Modelo lineal simple, con regi贸n de confianza al 95%")
p3
```

## Ejercicio 3
\textit{Calcula los intervalos de confianza para los par谩metros del modelo de nivel 99%.
Interpreta los resultados obtenidos.}
En el siguiente apartado, En primer lugar, establecemos el nivel de significaci贸n $\alpha$.
```{r alfa}
alfa <- 1 - 0.99
```

A continuaci贸n, hallamos los intervalos para 
El pivote es ((PASAR A LATEX)) beta0.gorro - beta0/(sqrt(var.gorro*(1/n+mX^2/(n*var.X))) que es una
T de Student con n-2 grados de libertad

```{r icbeta0mano}
beta0.cuantil <- qt(1-alfa/2, df=n-2); beta0.cuantil
beta0.extremoinferior <- beta0.gorro - beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.extremosuperior <- beta0.gorro + beta0.cuantil * sqrt(var.error * (1/n + mX^2/(n*var.X)))
beta0.IC <- c(beta0.extremoinferior, beta0.extremosuperior); beta0.IC
```

El pivote es ((PASAR A LATEX)) pivote beta1.gorro - beta1/sqrt(var.gorro/ (var.X * n)) que es una
T de Student con n-2 grados de libertad

```{r icbeta1mano}
beta1.cuantil <- beta0.cuantil
beta1.extremoinferior <- beta1.gorro - beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.extremosuperior <- beta1.gorro + beta1.cuantil*sqrt(var.error/(var.X * n))
beta1.IC <- c(beta1.extremoinferior, beta1.extremosuperior); beta1.IC
```

El pivote para la varianza del error ser谩 ((PASAR A LATEX))
pivote -> (n-2)*var.error^2/varianzaerror^2 que es una chi-cuadrado con n-2
grados de libertad
```{r icvarsmano}
var.error.cuantilinferior <- qchisq(alfa/2, df=n-2)
var.error.cuantilsuperior <- qchisq(1-alfa/2, df=n-2)
var.error.extremoinferior <- (n-2)*var.error^2/var.error.cuantilsuperior
var.error.extremosuperior <- (n-2)*var.error^2/var.error.cuantilinferior
var.error.IC <- c(var.error.extremoinferior, var.error.extremosuperior); var.error.IC
```

Pero tambi茅n podemos utilizar las funciones de R para hacerlo de forma autom谩tica:
- IC para beta0 y beta1 asumiendo que la varianza es desconocida
```{r icbeta0beta1}
confint(modelo, level=0.99)
```

No hay una automatizaci贸n del c谩lculo de la varianza del error

## Ejercicio 4
\textit{Realiza los contrates de significaci贸n asociados al intercepto y a la pendiente del
modelo de regresi贸n considerado. Interpreta los resultados obtenidos. En base a
los resultados obtenidos, 驴tendr铆a sentido considerar otro modelo m谩s sencillo?}
A continuaci贸n, realizaremos los contrastes de significaci贸n sobre el modelo con el objetivo de determinar si el modelo se podr铆a simplificar a uno con menos variables o no.
En primer lugar, realizaremos el contraste de forma manual a partir de los estad铆sticos de contraste basado en el pivote de la estimaciones puntuales previas:
```{r signifmano}
# Contraste de significacion para beta0
beta0.t <- abs(beta0.gorro) / (sqrt(var.error * (1/n + mX^2/(n*var.X)))); beta0.t
beta1.t <- abs(beta1.gorro) / (sd.error / sqrt(n*var.X)); beta1.t
# Rechazamos la hip贸tesis nula de que el modelo tiene origen de 0
beta0.t > beta0.cuantil 
# Rechazamos la hip贸tesis nula de que el modelo no tiene pendiente
beta1.t > beta1.cuantil
# El p-valor es 0 --> La hip贸tesis nula es falsa para cualquier nivel de signif. --> El modelo tiene un intercepto distinto de 0
beta0.pvalor = dt(beta0.t, df=n-2); beta0.pvalor
# El p-valor es 0 --> La hip贸tesis nula es falsa para cualquier nivel de signif. --> El modelo tiene una pendiente distinta de 0
beta1.pvalor = dt(beta1.t, df=n-2); beta1.pvalor
```

De esto deducimos que existen pruebas estad铆sticamente significativas de que $\beta_0 \neq 0$, lo cu谩l nos indica que el intercepto es distinto de 0. Por otro lado, tambi茅n existen pruebas de $\beta_1 \neq 0$, de d贸nde deducimos que realmente la variable explicativa influye en la variable respuesta. 

Alternativamente, podemos obtener los valores de estos dos contrastes de significaci贸n y su p-valor a partir de los datos presentes en el modelo de R. Para esto, usaremos la funci贸n summary:
```{r signifauto}
summary(modelo)
```
En concreto, los valores relevantes son el t-value y el Pr(>|t|) de las filas (Intercept) y X que se corresponden al valor observado del estad铆stico observado y su p-valor en el contraste sobre el intercepto $\beta_0$ y la pendiente $\beta_1$. Obtenemos los mismos datos que en el c谩lculo manual.

En base a los resultados obtenidos anteriormente, decidimos no simplificar m谩s nuestro modelo y continuar realizando regresi贸n lineal.

## Ejercicio 5
\textit{Si consideramos que la variable  toma 3 nuevos valores: 2, 4 y 6 unidades, proporciona intervalos de predicci贸n e intervalos de confianza para la media condicionada de la variable . Interpreta los resultados obtenidos.}

En este apartado, consideramos 3 nuevos valores para la variable explicativa $X = 2, 4, 6$. Para obtener intervalos de confianza para la media de Y condicionada a estos valores y de predicci贸n, es necesario comprobar primero que estos datos est谩n dentro del rango de observaci贸n de X. Esto es debido a que no sabemos como se comporta el modelo fuera del rango observado, y nuestro objetivo es predecir y no extrapolar.
```{r validacionnuevosdatos}
nuevosValores <- c(2, 4, 6)
# El rango est谩 contenido
min(X) < min(nuevosValores) && max(X) > max(nuevosValores)
# Construimos un data.frame  con los nuevos datos ya que predict necesita este formato para sus predicciones
nuevosDatos = data.frame("X" = nuevosValores)
```
Habiendo realizado esta comprobaci贸n, ya podemos obtener los intervalos utilizando la funci贸n predict sobre el modelo de R. Obtendremos ambos intervalos para los niveles de significaci贸n 0.95 y 0.99. ((TODO: REVISAR, ESTOS ESTN BIEN PERO DEBERAN SER CONSISTENTES CON OTRAS PARTES DONDE COJAMOS ALFAS ARBITRARIOS))

En primer lugar, pasando el argumento $\texttt{interval = "confidence"}$ obtenemos los asociados a la media condicionada.
```{r intmediacond}
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "confidence", level=0.99)
```
Y para obtener los intervalos de predicci贸n, los cu谩les ser谩n m谩s amplios que los anteriores, pasamos el argumento $\texttt{interval = "prediction"}$
```{r intprediccion}
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.95)
predict(modelo, newdata = nuevosDatos, interval = "prediction", level=0.99)
```
## Ejercicio 6 
TODO

## Ejercicio 7
  Las t茅cnicas de inferencia empleadas hasta el momento son ciertas bajo el supuesto de que las 4 hip贸tesis del modelo de regresi贸n lineal simple (linealidad, homocedasticidad, normalidad e independencia) se verifican. De lo contrario,
  no todas las interpretaciones obtenidas seguir铆an siendo v谩lidas. Por ejemplo, si no se cumplieran las hip贸tesis de homocedasticidad, normalidad e independencia, los intervalos de confianza que hemos obtenido no ser铆an v谩lidos.

### Linealidad
En primer lugar, podemos tratar de aventurar si se los datos siguen una tendencia lineal. Emplearemos una aproximaci贸n exploratoria, a trav茅s de una interpretaci贸n gr谩fica. Para ello, revisitemos la representaci贸n previamente definida.

```{r dispersion2, echo=FALSE}
representar()
abline(modelo, col="red", lwd=2)
```

Vemos que los puntos parecen distribuirse en torno a la recta de forma lineal. Si bien hay datos un tanto at铆picos, especialmente en los extremos, esto no es lo suficientemente significativo como para rechazar la hip贸tesis. Tampoco se ve un patr贸n evidente en los datos (es esto lo que debemos tratar de detectar, y no solo corroborar que haya el mismo n煤mero de puntos por encima/debajo de la recta, que no es suficiente como para indicar linealidad).

N贸tese que aunque se puede apreciar una menor concentraci贸n de puntos para valores de X comprendidos alrededor del valor 4, esto no es indicativo de una falta de linealidad. Dado que trabajamos bajo dise帽o fijo, se tiene que achacar a decisiones sobre las condiciones de medici贸n o al propio dise帽o del experimento. Esta observaci贸n se puede comprobar a trav茅s del siguiente cuadro:

```{r tabla}
# Representamos el n煤mero de valores de X en cada intervalo de longitud 0.5, comenzando desde el mayor entero menor
# o igual que el dato m铆nimo, y finalizando en el menor entero mayor o igual que el dato m谩ximo.
table(cut(X, breaks=seq(from=floor(min(X)), to=ceiling(max(X)), by=0.5)))
```

Con el objetivo de realizar una prueba m谩s precisa, planteamos el siguiente contraste de hip贸tesis. Como hip贸tesis nula tenemos que la variable respuesta siga el modelo lineal simple que hemos estado considerando, y como hip贸tesis nula, que siga un modelo parab贸lico, donde hay dependencia de la variable explicativa al cuadrado:
$$
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=\beta_0+\beta_1X+\beta_2*X^2\epsilon
\end{cases}
$$

Ejecutamos la prueba:

```{r resettest}
# Empleamos power = 2 porque estamos considerando una alternativa cuadr谩tica
resettest(modelo, power = 2)
```

Vemos que el p-valor es de 0.7613. INTERPRETAR.

No obstante, este contraste solo nos ha aportado informaci贸n sobre la equiparaci贸n con un modelo cuadr谩tico. Si busc谩ramos una confirmaci贸n perfecta, te贸rica, deber铆amos seguir contrastando con todos los valores de power. Dado que esto es impracticable experimentalmente, podemos plantearnos en su lugar un contraste m谩s general, con una alternativa no par谩metrica:
$$
\begin{cases}
H_0: Y=\beta_0+\beta_1X+\epsilon\\
H_a: Y=m(X)+\epsilon
\end{cases}
$$

Haciendo uso del paquete _sm_, realizamos la prueba de hip贸tesis:
```{r smregresion}
         
# Importamos rpanel para abrir un panel interactivo para la representaci贸n
# Los valores que sabemos interpretar son los que aparecen con las opciones por defecto
# Indicamos test=T para que se nos muestre un p-valor.
sm.regression(X, Y, model="linear", panel=T, test=T)
```

La interpretaci贸n de la figura resultante es la siguiente. Con una l铆nea negra nos aparece marcada una estimaci贸n no param茅trica de la regresi贸n (sin asumir linealidad), y en azul, una regi贸n de confianza para el modelo lineal simple. Vemos que la l铆nea negra se encuentra siempre dentro de la regi贸n azul. Por tanto, podemos asumir que la hip贸tesis nula es cierta, esto es, que los datos verifican la hip贸tesis de linealidad.
FALTA ANALIZAR EL P-VALOR


### Homocedasticidad
Contrapongamos ahora los residuos del modelo a la variable explicativa. Se muestra tambi茅n el diagrama de dispersi贸n original:
```{r dispersionresiduos, echo=FALSE}
par(mfrow=c(1,2))

representar()
abline(modelo, col="red", lwd=2)

residuos <- modelo$residuals

plot(X, residuos,
   main="Diagrama de dispersi贸n", pch=16,
   sub="Subt铆tulo")
abline(h=0, col="gray", lwd=2)

par(mfrow=c(1,1))

```

Queremos comprobar ahora si la varianza del error, $\sigma^2$, es la misma independientemente del valor que tome la variable explicativa. Vemos que la distribuci贸n de los residuos en el diagrama no sigue un patr贸n evidente, y que su desviaci贸n con respecto a la recta $x=0$ parece ser la misma sin importar el intervalo de X considerado. 

Tampoco sobre el diagrama de dispersi贸n de la variable respuesta observamos una tendencia significativa acera de las desviaciones con la recta de regresi贸n. En conjunci贸n con lo anterior, podr铆amos aventurar, a primera vista, que los datos muestrales son verdaderamente homoced谩sticos.

S铆 destacamos que la interpretaci贸n para la regi贸n central, en aproximadamente $(4, 4.5)$, puede no ser muy precisa, por falta de datos. Sin embargo, esto no basta para desmentir la hip贸tesis de homocedasticidad.

Para tener una confirmaci贸n precisa, nos planteamos el siguiente contraste de hip贸tesis:
$$
\begin{cases}
H_0: \text{modelo homoced谩stico}\\
H_a: \text{modelo heteroced谩stico}
\end{cases}
$$

Ejecutamos un test de Harrison-McCabe con R, haciendo uso del previamente cargado paquete _lmtest_:
```{r hmctest}
hmctest(Y~X)
```
El p-valor es de 0.763.


### Normalidad
Para corroborar que el error tiene distribuci贸n normal, haremos varias representaciones gr谩ficas que nos permitan intuir si la hip贸tesis se ajusta a los datos. Trabajaremos con los residuos estandarizados, pues no tienen la misma varianza y la correlaci贸n entre cada 2 de ellos puede ser distinta (provienen de distribuciones diferentes).

Presentamos 3 gr谩ficos: un histograma, un boxplot y un qqplot (para el cual necesitamos la librer铆a _car_), aunque centraremos nuestra atenci贸n en el 煤ltimo de ellos, el m谩s relevante en lo que concierne al estudio de la normalidad.

```{r representacionnormalidad, echo=FALSE}
residuos.estan = rstandard(modelo)

par(mfrow = c(1, 3 )) 

hist(residuos.estan, col=c(viridis(n=5, begin=0, end=0.8), viridis(n=1, begin=1), viridis(n=5, begin=0.8, end=0)))
rug(residuos.estan)

boxplot(residuos.estan, col="gray")

qqPlot(residuos.estan)
```

En el histograma podemos apreciar una cierta asimetr铆a hacia la derecha (valores m谩s altos). En el boxplot o diagrama de caja vemos que la media est谩 centrada en el centro de la caja, un buen indicador. No obstante, la cola izquierda es de una longitud ligeramente mayor, lo cual es indicativo de la asimetr铆a mencionada, al estar los datos m谩s concentrados alrededor de valores m谩s altos.

El QQPlot o diagrama cuantil-cuantil nos presenta una comparativa entre los cuantil muestrales de los residuos estandarizados y los cuantiles te贸ricos de una normal est谩ndar. Si los residuos estandarizados presentaran una distribuci贸n normal de media 0 y varianza 1, se situar铆an alrededor de la recta diagonal resaltada. En nuestro caso, vemos que en la zona central el ajuste es bueno, pero hay una cierta desviaci贸n en las colas. Esto es especialmente notorio en la superior, donde los cuantiles muestrales son algo inferiores a los cuantiles te贸ricos de una normal, que es l贸gico y coherente con la asimetr铆a indicada anteriormente.

Ahora bien, una representaci贸n visual es solamente un apoyo al estudio, y no podemos inferir de ella una conclusi贸n estad铆sticamente definitoria. Para ello , emplearemos  directamente un test de bondad de ajuste sobre los errores estandarizados con respecto a una distribuci贸n normal. Aunque hay varias opciones adecuadas, como el test de Kolmogorov-Smirnov y el test de Lilliefoids, el m谩s ampliamente usado con este prop贸sito es el test de Shapiro-Wilk, especialmente dise帽ado para contrastes de normalidad:

$$
\begin{cases}
H_0: \epsilon\text{ sigue una distribuci贸n normal}\\
H_a: \epsilon\text{ no sigue una distribuci贸n normal}
\end{cases}
$$

Ejecutemos pues el contraste de especificaci贸n mencionado:
```{r shaphiro}
shapiro.test(residuos.estan)
```

Tambi茅n podemos comprobar los resultados de otros tests:
```{r kslillie}
# TODO FIXME
# el argumento y esta ausente
# ks.test(residuos.estan)
lillie.test(residuos.estan)
```

Una observaci贸n adicional: en este caso, tenemos que el tama帽o de la muestra, n, es mayor que 30, de modo que se pueden despreciar las impurezas debidas a utilizar los residuos en el estudio de la normalidad, en lugar de los errores (que no est谩n sujetos a la aplicaci贸n del ajuste de m铆nimos cuadrados).
```{r inputsize}
n
```


### Independencia
De entre las 4 hip贸tesis con las que trabaja el modelo, la independencia de los errores es la m谩s dif铆cil de corroborar. No tenemos informaci贸n acerca del proceso de recogida de muestras, por lo que no podemos garantizarla en base a que los datos hayan sido medidos sobre objetos o individuos de forma independiente.

Debido a la complejidad inherente a este apartado, nos limitaremos a comprobar la independencia temporal. Para ello, asumiremos que nuestros datos han sido medidos a lo largo del tiempo. 

Nos preguntamos entonces si existe alg煤n tipo de relaci贸n entre las observaciones, esto es:
$$
\begin{cases}
H_0: \epsilon\text{ son incorrelacionados}\\
H_a: \epsilon\text{ son correlacionados de orden k}
\end{cases}
$$
En el contraste planteado, $k\in\mathbb{N}$, $k>1$, es el retardo, esto es, la separaci贸n entre los instantes de tiempo que influyen sobre el instante actual. As铆, fijado un k y dados unos errores 


BONDAD DE AJUSTE ES EL COEFICIENTE DE DETERMINACIN (ES UNA MEDIDA DE CUNTO DE BUENO ES EL MODELO). EL R^2 AJUSTADO ES OTRA MEDIDA DE BONDAD DE AJUSTE. TAMBIN HAY CONTRASTES. EST EN EL SUMMARY.

ACEPTAR LA H0 EN CONTRASTE LINEALIDAD POLINMICO SOLO SIGNIFICA QUE MI MODELO ES MEJOR QUE UN POLINMICO DE ORDEN 2, 3...

EL SM TE LO CONTRASTA CON ALTERNATIVA NO PARAMTRICA -> ES MEJOR MI MODELO QUE CUALQUIER OTRA COSA? CON HACER ESTE ES SUFICIENTE

a veces las formas raras en homocedasticidad (qqplot) se pueden deber a falta de linealidad. Es m谩s conncluyente el contraste


HAY QUE FIJAR EL ALFA DESDE EL PRINCIPIO. METER YA DESDE LA INTRODUCCIN. EN ESTE CASO TENDREMOS QUE FIJAR ALFA = 1% (NIVEL 99%) POR EL APARTADO 3

